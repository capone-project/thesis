\section{Implementation}

\subsection{Services}

\subsubsection{Capability Service}

\begin{figure}[H]
    \centering

    \begin{sequencediagram}
        \newthread{r}{Requester r}
        \newinst[2]{e}{Entity e}
        \newinst[2]{s}{Service s}
        \newinst[2]{c}{Capability Service}

        \mess{e}{Register}{c}
        \postlevel

        \begin{call}{r}{Request(e, s, params)}{c}{Capability}
            \postlevel
            \begin{call}{c}{Ask(r, s, params)}{e}{Capability}
                \postlevel
                \begin{call}{e}{Initiate(params)}{s}{Capability}
                \end{call}
                \postlevel
            \end{call}
            \postlevel
        \end{call}

        \postlevel

        \begin{messcall}{r}{Start}{s}
            \postlevel
        \end{messcall}

        \prelevel
    \end{sequencediagram}
    \caption{Capability Request}
\end{figure}

\lstinputlisting[caption=Capability Service Interface,label=src:capability-protos,float,floatplacement=h]{../../source/sd/proto/capabilities.proto}

\subsubsection{Invoke Service}
\label{sec:invoke-service}

\begin{figure}[H]
    \centering

    \begin{sequencediagram}
        \newthread{c}{Client}
        \newinst[4]{s}{Service}
        \newinst[4]{i}{Invoker}

        \begin{call}{c}{Initiate(Parameters)}{s}{Service Session}
            \begin{call}{s}{CreateSession()}{s}{Capability}
            \end{call}
        \end{call}

        \postlevel

        \begin{call}{c}{Initiate(ServiceSession)}{i}{Invoker Session}
            \begin{call}{i}{CreateSession()}{i}{Capability}
            \end{call}
        \end{call}
        \postlevel

        \begin{messcall}{c}{Start}{i}
            \begin{messcall}{i}{Start}{s}
                \postlevel
            \end{messcall}
            \prelevel
        \end{messcall}
        \prelevel
    \end{sequencediagram}

    \caption{Invoke Service}
\end{figure}

\subsubsection{xpra Service}

\begin{figure}[H]
    \centering

    \begin{sequencediagram}
        \newinst{x}{Xpra server}
        \newthread[4]{c}{Client}
        \newinst[4]{s}{Display service}

        \begin{call}{c}{Start(port)}{x}{instance}
        \end{call}

        \postlevel

        \begin{messcall}{c}{InitiateConnection()}{s}
            \postlevel
            \begin{call}{c}{Request(xpra-port)}{s}{session}
            \end{call}
        \end{messcall}

        \postlevel

        \begin{messcall}{c}{InitiateConnection()}{s}
            \postlevel
            \begin{messcall}{c}{Connect(session)}{s}
            \end{messcall}

            \postlevel

            \begin{messcall}{s}{Tunneled data exchange}{x}
                \postlevel
            \end{messcall}
            \prelevel
            \prelevel
            \prelevel
            \begin{messcall}{x}{}{s}
            \end{messcall}
        \end{messcall}
    \end{sequencediagram}

    \caption{Xpra Service}
\end{figure}


\subsection{Benchmarking}

We will now provide measurements on how the project scales under different conditions.
There are three major measurements we are interested in and which directly influence the framework's usability.
\begin{description}
    \item[Throughput]\hfill\\
        How much data are we able to write through a channel in a certain amount of time.
        This statistics is of particular importance when performing bulk traffic, e.g. when connected to a file service or forwarding the user's desktop to a service.
    \item[Connection establishment]\hfill\\
        How long does it take to negotiate a connection with remote party.
        This is experienced by users which try to connect to a service and determines how long it will take until initial data is transferred between two entities.
    \item[Input latency]\hfill\\
        How long does it take until data submitted on either the user's or server's side arrives at the other party.
        This is of importance for interactive services like input forwarding.
\end{description}

We will test throughput and connection establishment with the low-level primitives used inside the framework.
Two small utilities (\lstinline{sd-bench} and \lstinline{sd-latency}) have been implemented to handle these and conduct the tests.
Both programs open a TCP server socket and then spawn a new thread which connects to the open socket.
They will then perform the actions specific to the benchmark.

Timings are obtained by invoking the POSIX function \lstinline{clock_gettime} with a monotonic clock.
Monotonic clocks do not jump in time when certain events happen on the system, e.g. when timezone changes or when \lstinline{adjtime} is called by some kind of NTP implementation.
On most systems, the \lstinline{clock_gettime} function provides timings in nanosecond resolution.

As timings are inherently inaccurate on computer systems due to interference with other programs, the kernel's scheduler, frequency scaling and more effects we are averaging the timing over repeated invocations of the core functionality that is to be benchmarked.
Experimentation showed results with errors in the range of $\pm2\%$.
This is precise enough in order to make observations as we usually operate in the range of multiple orders of magnitude where results are sufficiently distinct.

To increase reproducability on multi-core systems, both threads are fixed .

\subsubsection{Throughput}

\begin{figure}[h]
    \centering

    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=200,xmode=log,xlabel=Block length (in bytes)]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}
                \end{axis}
            \end{tikzpicture}
        }
        \caption{256 bytes of data}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=400,xmode=log,xlabel=Block length (in bytes)]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}
                \end{axis}
            \end{tikzpicture}
        }
        \caption{1 kilobyte of data}
    \end{subfigure}

    \vspace{1em}

    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=650,xmode=log,xlabel=Block length (in bytes)]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}
                \end{axis}
            \end{tikzpicture}
        }
        \caption{100 kilobytes of data}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=650,xmode=log,xlabel=Block length (in bytes)]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}
                \end{axis}
            \end{tikzpicture}
        }
        \caption{10 megabyte of data}
    \end{subfigure}

    \caption{Sending data with different block lengths}
\end{figure}

The fours graphs display measurements for the different message sizes of 256 bytes, 1 kilobyte, 100 kilobytes and 10 megabytes.
Each of the figures has three different graphs representing the different scenarios for transfer of data on the same host and in LAN respectively WAN.
The x axis represents different block lengths in bytes used to split outgoing messages.
Please note that a logirithmic scale is used for block lengths.
The y axis represents the throughput achieved in megabytes per second averaged over the 1GB of data sent.
A higher value is better.

Additional constant dotted lines have been added to represent target throughput for ethernet (red, 120MB/s) and internet (brown, 10MB/s).connections .
These aim to put an estimated maximum achievable throughput which aids at better comprehending the chosen block length.

\medskip

Let us first discuss graphs \ref{fig:block-length-benchmark-256b} and \ref{fig:block-length-benchmark-1kb} as examples for transferring small messages to a remote host.

What stands out is that there throughput caps out at block lengts of 512 bytes for 256 byte messages and at block lengths of 1500 bytes for 1024 byte messages, respectively.
The reason for this is obvious: these are the smallest block lengths where the whole message fits into.
Regard that for a message of length $l$, the smallest block length that is big enough to fit is $l + 16 + 4$.
With smaller block lengths we have to send multiple blocks to transmit the whole message and with bigger messages we have to encrypt additional padding.
So the optimal block length for small messages is the smallest one where the whole message with metadata fits into.

One more interesting thing to observe is that with increasing latency, throughput decreases and features of the graphs seem to diminish.
While the spike in throughput is easily visible on 0ms and 2ms of latency, it becomes barely recognizable on 20ms of latency.
The effect of feature-flattening seems to get even more obvious the more data is sent, but this is effect results from a different maximum throughput value.

Let us take a look at graphs \ref{fig:block-length-benchmark-100kb} and \ref{fig:block-length-benchmark-10mb} now for examples of bulk transfer.
The effect of latency on throughput is very interesting for these graphs - while throughput constantly increases when there is no latency at all, it caps out at 200MB/s for 2ms of latency and at 50MB/s for 20ms of latency.

For 2ms of latency the cap is at around a block length of 1500 bytes.
The value of 1500 was included in the benchmarks as this is a typical size of the maximum transmission unit (MTU) for ethernet connections.
The MTU is the size of the largest amount of data that can be sent in a single ethernet frame without requirement to split the frame into multiple frames.
With this information, we have a possible explanation as to why throuput caps out at around 1500 bytes and decreases afterwards for 2ms of latency, while it steadily increases for 0ms of latency.
Sending two frames with latency will obviously have an impact on throughput, while it does not have a real impact when there is no latency.

\medskip

These benchmarks do not pay attention to maximum bandwith available in LAN or WAN settings.
Usually, we cannot achieve more than around 100 megabytes per second in Gigabit Ethernet settings and around 10 megabytes per second in WAN settings.
We should honor this limitation when determining an optimal block length.

For small packages we are not able to reach the target throughput at for 2ms of latency and fail to meet the target starting at block lengths of 1024 for 20ms of latency when sending 256 byte messages.
For bulk transfer we start to hit the target in all scenarios when using a block length of 512 bytes.

\medskip

Let us subsume our findings from thesn benchmarks:
\begin{itemize}
    \item the optimum block length for short messages is the minimum block length able to fit in the complete message
    \item increasing block lengths will penalize short messages due to encryption overhead
    \item optimizing block length with high latencies is not useful due to throughput being near-flat
    \item optimal block length should not exceed length of the MTU (e.g. 1500 bytes)
\end{itemize}

To compromise between throughput for small and bulk traffic we chose a block length of 512 bytes.
It is the smallest block length able to achieve all target throughputs except for small messages with 2ms of latency, but we do not expect to need high throughput for small messages.

It may be desirable to make the block length configurable per service.
Services usually know their communication patterns and can thus optimize for the respective scenario they require.
Currently no such feature exists, but the block length is trivially changable at compile time and as such it would a small feat to make block lengths configurable at runtime.

\subsubsection{Connection latency}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[ylabel=Connection time (in ms),xmode=log,xlabel=Block length (in bytes)]
            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{0}] {data/latency.csv};
            \addlegendentry{0ms latency}

            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{2}] {data/latency.csv};
            \addlegendentry{2ms latency}

            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{20}] {data/latency.csv};
            \addlegendentry{20ms latency}
        \end{axis}
    \end{tikzpicture}
    \caption{Connection latency}
\end{figure}

\subsubsection{Input latency}

% vim: ft=tex tw=0
