\section{Implementation}

In this chapter we will now discuss how the architecture discussed in the previous section is actually implemented.
The application is split into two parts, the Android app as well as the framework used to implement the complete server component as well as a command-line driven client.
While the app is written in Java, the main programming language used to program for the Android operating system, the other part is completely written in C.

In this chapter, we will only cover the implementation of the C part containing the core logic.
The Android-specific part is mostly uninteresting, as most of the code is related to handling the user interface with only a small amount of code related to the actual protocol implementation.
As the complete protocol including the client part has also been implemented in C, no gains are expected in describing the Android application itself other than getting knowledge on the Android ecosystem in a whole.

\subsection{Channel}
\label{sec:channel}

Nearly all parts of the application perform network operations, reading and writing data sent from the remote side.
As network operations are a rather complicated part in the C programming language with many pitfalls, the complete code regarding network operations has been encapsulated inside a structure called a \emph{channel}.
Channels handle the issue of connection establishment, receiving data and writing data to another host, as well as handling encryption and encoding respectively decoding of the low-level protocol discussed in section \ref{sec:low-level-protocol}.

All channels created initially operate unencrypted.
The most basic functions provided by a channel are the read and write operations, which get as arguments a pointer to a buffer as well as the buffer's length.
Recall that all messages sent via our low-level protocol are split into blocks of a fixed length -- instead of having the user care about this, the read and write functions transparently split the message into blocks, prefixing the initial block with the message's overall length and re-assemble them on the receiving side.

Note that the current implementation uses blocking sockets without timeouts or keep-alive.
While this greatly simplifies logic related to network operations, this becomes an easy attack vector on the server-side where multiple clients connect to it and then simply keep the connection open while the server waits for incoming messages.
In later iterations of the framework, we should instead employ countermeasures to this and return an error if receiving or writing data to the channel times out or the remote has dropped the connection.

Considering the complete protocol is built upon Google Protobuf \cite{varda2008protocol}, the channel provides functions to directly write Protobuf messages to a socket and read Protobuf messages from a socket.
The interface is held very simple in that the function simply receives a pointer to the Protobuf structure as well as a description of the Protobuf, which is automatically generated by the Protobuf C compiler.
On the sending side, we now serialize the message and send it by invoking the previously mentioned send and receive functions, which handle message splitting.
The receiver now deserializes the message into the Protobuf structure and hand it back to the caller.

Besides handling encoding of messages and Protobufs, channels also handle encryption.
While they are initially sending messages in plain text only, encryption may be enabled by providing a symmetric key to the channel.

When a new key is provided to the channel, it will initialize nonces contained inside the channel struct to have the value $0$ for the client-side and $1$ for the server side.
Obviously, each side is required to know whether it is a client or a server, but this is always the case.
Further note that it is safe to have deterministic nonces as we always assume that the given symmetric key is a newly generated session key only and will be used only once.

When data is sent or received, either the local or remote nonce will get incremented by $2$.
Given that nonces are 24 bytes long, the chance of collision of nonces due to a integer overflow is insignificant.
The nonces are incremented on the block level instead of on a message level.
Assuming it was instead incremented after sending a message, messages containing two blocks which are equivalent to each other due to repeating patterns in the message would be encrypted with the same nonce, leaking information.
As such, it is important to handle nonces on the block level.

\subsection{Capabilities}
\label{sec:capabilities}

The protocol makes usage of capabilities to guard access to all sessions.
Capabilities are discussed later on in section \ref{sec:access-control}, but here we will discuss the actual implementation of capabilities.

As we will discuss later on, our capabilities are implemented in a similar fashion as in \cite{gong1989secure}:
Each server has an internal list of capabilities, where each capability references a specific session by means of a session identifier.
When we want to give out capabilities to a third party, we generate a cryptographically protected capability which references our internal capability.

Upon generation, each internal capability will have a pair of session identifier as well as a 256 bit random secret which is known only to the server itself and may not leak to the outside, as it is used to guard the capability.
As such, it is required that the random number generated is generated by a cryptographically secure random number generator.
We rely on the implementation of libsodium to generate cryptographically secure random numbers for the internal capabilities.

When we now want to grant a new capability to access the internal capability $c0 = (objectid0, secret0)$ for a user with public key $pk1$ with rights $r1$, we do so by calculating
\begin{align*}
    secret1 &= hash(pk1 || objectid0 || rights1 || secret0) \\
    c1 &= (objectid0, r1, secret1)
\end{align*}.
That is, the generated capability now has implicit knowledge about the referenced internal capability as well as its random secret, the user who requested the capability as well as granted access rights.

So when a user now presents his capability, we will iterate through all available internal capabilities, checking for each capability whether the object identifier matches and if so, verify $secret1$.
To do so, we again calculate $hash(pk1 || objectid0 || rights1 || secret0)$, where we know $pk1$ from the initial session establishment, $objectid0$ and $rights1$ from the transmitted capability and $secret0$ has been retrieved from the internal capability identified by $objectid0$.
If the calculated hash matches the hash provided by the user's capability, access is granted.

For more details on the capability implementation, please refer to \cite{gong1989secure} and section \ref{sec:access-control}.

\subsection{Services}
\label{sec:services}

Next to the protocol as it has been specified in section \ref{sec:architecture}, all functionality provided by the server is implemented in terms of services.
A service as such is a single unit providing usually providing a single functionality to users.

In order to start using service, the user first has to establish a service session and then subsequently start using the session (see section \ref{sec:session-initiation} for more details).
When establishing the service session, the user has to specify a set of parameters.
These parameters are passed on to the service when the created session is started by the user and may influence its behavior.
Assuming a shell service which provides the functionality to execute a program, the parameters may for example include which program to execute, what its parameters are and possibly environmental variables passed to the service.

There are currently five exemplary services implemented:
\begin{description}
    \item[Invoke service]\hfill\\
        Invoke services handle the use case where a user wants to execute a service on certain server hosting the invoke service.
        This is used heavily when the Android controller application is used, which will usually not execute provided services itself but instead cause another server (which provides the invoke service) to start the service.
    \item[Capability service]\hfill\\
        Capability services handle the use case where a user wants to ask another user for the permission to execute a service in his name.
    \item[Xpra service]\hfill\\
        Xpra is a specific implementation of an X11 server session manager.
        When applications are started in the Xpra server, it is possible to attach to this application on another computer and display the application on another screen.
    \item[Synergy service]\hfill\\
        Synergy handles forwarding of input devices, that is mouse and keyboard, to another computer.
    \item[Execution service]\hfill\\
        The execution service provides an interface to execute applications on a server.
\end{description}

The current interface how service plug-ins are instantiated is very simple.
Each service has a set of functions to retrieve metadata on the service or to handle the connection to a server or from a client.
The aim of this design is to have services pluggable in the future, that is we want to have a true plug-in-based approach.

Currently, all services are statically linked into the server's and client's executable.
But when a clean interface exists to separate each service from the main executable, we are later able to cut out these services and dynamically link them in as shared object later on, so that they can be linked on-demand.
This keeps the server lean in such a way that it only implements core functionality while still being extendable.

Being extendable and being able to only link to a certain set of service objects at runtime is of importance for cross-platform functionality.
Not every services may be available on all platform, e.g. when services link against the X server they might not easily be available on Windows.
In order to avoid having to handle all plug-ins conditionally of the build platform in the source code itself, we could easily extend the build system to build only a certain set of services.
In addition, it would become simpler for third-party developers to create and tie in additional services.

\medskip

To guarantee a working plug-in system we have to have a working plug-in-interface, though.
The current service interface consists of the following functions:
\begin{itemize}
    \item An init function initializing the plug-in
    \item A function reporting the service's version
    \item A function reporting parameters the service may be invoked with
    \item A handler function which handles the server side of a session
    \item An invoke function which handles the client side of a session
\end{itemize}

The heart of each plug-in is contained in the \lstinline{handler} and \lstinline{invoke} functions.
When a client wants to execute a service and the service session has been started, the client's executable will execute the \lstinline{invoke} function of the service plug-in, receiving the channel and the client's configuration as arguments.
It will then perform all service-specific actions and communicate with the remote side via the channel, which transparently handles encryption.

The \lstinline{handle} function is the counterpart to \lstinline{invoke}.
Upon a client connecting to a server and starting a session, the server will execute \lstinline{handle} for the respective plug-in, passing in the session with its parameters as well as the channel connected to the client.

It remains to be seen if this interface design is sufficient to handle different use-cases required by different service plug-ins.

\subsubsection{Invoke service}
\label{sec:invoke-service}

The invoke service provides the ability to start a remote service on the server providing the invoke service.
There are up to three parties involved in the process:
\begin{description}
    \item[Controller]
        The entity controlling the process.
        The controller is the one directing the invoke service to invoke another service.
    \item[Invoker]
        The service providing the ability to start a service on the server it is hosted on.
    \item[Service]
        The service being started by the Invoker.
        While this service will often reside on another server than the invoke service, this is not a requirement.
\end{description}

References to these specific parties will be written with a capitalized first letter.
The whole process of service initiation has three steps:
\begin{enumerate}
    \item The Controller creates a new session with the Service that is to be started later by the Invoker.
    \item The Controller creates a new session with the Invoker, passing the capability for the session just created with the Service.
    \item The Controller starts the session created with the Invoker, causing the Invoker to start the session on the Service.
\end{enumerate}

These steps are visualized in an UML flow diagram in figure \ref{fig:invoke-service}.
Each entity has a public identity represented by the lowercase letter following its name.
The following functions are used in the diagram:
\begin{description}
    \item[Request($i$, $p$) $\rightarrow$ $c$]
        Request a new session with a set of parameters represented as key-value pairs for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newthread{c}{Client $c$}
        \newinst[3]{s}{Service $s$}
        \newinst[3]{i}{Invoker $i$}

        \begin{call}{c}{Request($i$, $p=\{\ldots\}$)}{s}{Capability $c_1$}
            \begin{call}{s}{CreateSession($c$, $i$, $p$)}{s}{Capability $c_1$}
            \end{call}
        \end{call}

        \postlevel

        \begin{call}{c}{Request($c$, $p=\{\text{service}=s, \text{cap}=c_1\}$)}{i}{Capability $c_2$}
            \begin{call}{i}{CreateSession($c$, $c$, $p$)}{i}{Capability $c_2$}
            \end{call}
        \end{call}
        \postlevel

        \begin{messcall}{c}{Start($c_1$)}{i}
            \postlevel
            \begin{messcall}{i}{Start($c_2$)}{s}
                \postlevel
            \end{messcall}
            \prelevel
        \end{messcall}
        \prelevel
    \end{sequencediagram}

    \caption{Invoke Service}
    \label{fig:invoke-service}
\end{figure}

On first sight, the order of session establishment may seem a bit puzzling, as the Service session is created before the Invoker session is being created.
But actually this results out of the protocol's design: no entity is able to create a session in name of another entity when it does not know about the other entity's long term signature key.
As the Client wants to create a session which can be started by the Invoker, he will have to create a new capability which he owns but which the Invoker may use.

This use case is exactly why capabilities differentiate between their owners and their invokers:
the owner is the entity who creates the capability and who may destroy the capability before it has been used, but he is unable to use the capability.
The invoker of a capability is only able to use a capability which has been granted by either himself when creating a new session or which has been passed by another entity.

Returning back to the invoke service it now becomes obvious why the Client creates the session with the Service, as only he is able to create a session in his own name.
It would theoretically be possible for the Invoker to create the session himself, but assuming the Service has some kind of access control he might either not be allowed to create sessions or he may not be allowed to create sessions capable of accessing data belonging to Client.

All subsequent steps are now trivial:
Given the session just created, Service returns a capability which can be used by Invoker to the Client.
Client now creates a new session with Invoker, passing on the capability as well as specifying the address of the service that is to be invoked.

When the Invoker session has been created, Client starts it, causing the Invoker to retrieve the passed on capability for Service from the session parameters and connects to the session on Service.

\subsubsection{Capability service}
\label{sec:capability-service}

The capability service solves the use case where an entity desires the ability to invoke a service in the name of another service.
That is it is the direct contrary to the invoke service, which can be used to push a capability to an invoker, in that the capability service pulls a capability from another entity.

Ideally, the capability service would not be required at all but instead, a requester would just directly ask another entity for permissions to execute a certain service.
But the requirement to directly connect to another entity requires the requester to always know of the address of the entity he wishes to ask.
As it may be very likely that the person asked for the capability uses a mobile phone with the Android application as a controller, the address might not be as stable as one would wish in this case.
Furthermore, it might be impossible to establish a direct connection when entities are in different networks, which usually use network address translation and do not allow direct connections to arbitrary ports.

In order to solve this problem, the capability service was developed as a means to forward capability requests between a requesting entity and a requested entity.
In fact the service does nothing more than allow entities to register themselves at the server and then subsequently forwards requests from other entities to registered entities and sending back capabilities created from accepted requests.
So it can be regarded as some kind of proxy service.

There are four participating entities which we will now define.
As before, we will subsequently refer to these entities by upper-casing the first letter.
\begin{description}
    \item[Client]\hfill\\
        The Client wishes to connect to the Service in the name of Registrant.
    \item[Registrant]\hfill\\
        The Registrant is an entity registered at the Capability Service.
        He is responsible for accepting or rejecting capability requests sent by Client.
    \item[Service]\hfill\\
        The Service is the service for which capabilities are requested for.
    \item[Capability Service]\hfill\\
        The Capability Service is a well-known service where entities may register to become Registrants or where capability requests are sent to by Clients in order to ask for permissions.
\end{description}

The process of capability requests involves five steps:
\begin{enumerate}
    \item The Registrant connects to the Capability Service
    \item The Client requests a capability from Registrant to invoke Service with a set of parameters by sending a request to Capability Service
    \item Capability Service forwards the request to Registrant
    \item Registrant decides if the request should be accepted or rejected.
        If it accepted, he creates a new session on Service for Client and send the capability to Capability Service
    \item Capability Service forwards the Capability to Client, who can now start the session on Service
\end{enumerate}

The whole process is visualized in figure \ref{fig:capability-request}.
The following functions are used in the diagram:
\begin{description}
    \item[Register()]\hfill\\
        Creates and starts a session with a Capability Service to become a registrant.
    \item[CapRequest($r$, $s$, $p$) $\rightarrow$ $c$]\hfill\\
        Request permissions to start service $s$ in the name of registrant $r$ with the set of parameters $p$.
        Returns a capability $c$ usable by the requester for service $s$.
    \item[Ask($c$, $s$, $p$) $\rightarrow$ $c$]\hfill\\
        Ask Registrant to create a capability for the client $c$ to invoke service $s$ with a set of parameters $p$.
        Returns a capability $c$ usable by the client $c$ if the registrant accepts the request.
    \item[Request($i$, $p$) $\rightarrow$ $c$]
        Request a new session with a set of parameters represented as key-value pairs for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newthread{c}{Client c}
        \newinst[1]{r}{Registrant r}
        \newinst[2]{s}{Service s}
        \newinst[2]{cap}{Capability Service}

        \mess{r}{Register}{cap}
        \postlevel

        \begin{call}{c}{CapRequest($r$, $s$, $p=\{\ldots\}$)}{cap}{Capability $c_1$}
            \postlevel
            \begin{call}{cap}{Ask($c$, $s$, $p$)}{r}{Capability $c_1$}
                \postlevel
                \begin{call}{r}{Request($c$, $p$)}{s}{Capability $c_1$}
                    \begin{call}{s}{CreateSession($r$, $c$, $p$)}{s}{Capability $c_1$}
                    \end{call}
                \end{call}
                \postlevel
            \end{call}
            \postlevel
        \end{call}

        \postlevel

        \begin{messcall}{c}{Start($c_1$)}{s}
            \postlevel
        \end{messcall}

        \prelevel
    \end{sequencediagram}

    \caption{Capability Request}
    \label{fig:capability-request}
\end{figure}

Let us now take a more detailed look at the steps.
The initial step is the registration of the Registrant.
The Capability Service needs to know where to send incoming capability requests to.
As such, entities who want to be able to answer capability requests need to register with the Capability Service in order to be able to retrieve the requests.

The registration is very simple in that a new session is created and opened with the Capability Service which, where the session is created as a \emph{Registrant} session.
Upon starting the session, the connection between Registrant and Capability Service will be kept alive and used to relay incoming requests.
Intuitively, one Capability Service can accept multiple Registrants at the same time.
For multiple Registrants with different identities the service works as one might expect:
Upon an incoming request, the Capability Service compares the requested identity with the identities of Registrants -- if one Registrant matches, the request will be forwarded to him.
Even though it is possible for the same entity to register twice at a Capability Service, this does not really make sense currently as the capability request is only forwarded to the first Registrant matching the entity requested by an incoming request.
This might change in future to either allow only one Registrant having the same identity at the same time or by forwarding the request to all matching Registrants, waiting for the first one to accept.

Independent of the registration, Clients may send capability requests to the server.
Each capability request contains whom to ask for permissions, which service the Client wants to have a capability for and a set of parameters which should be used to establish a session.
The request is sent to the Capability Service, which will now search its Registrants for one matching with the requested entity.
If one is found, the Capability Service will forward the capability request together with the entity of the Client asking for the capability to the matching Registrant.

As the Registrant receives the Capability Request, he will have to somehow determine if the requesting entity should be allowed to invoke the service as he requests or if the request should be rejected.
If he accepts the request, he will create a new session with Service for Client with the forwarded parameters, retrieves the newly created capability and forwards it to the Capability Service, which will subsequently forward the capability to the Client.
The Client is now able to use the capability to start a session with Service.

\medskip

The Registrant should be further explained now.
Often, the Registrant will be a human being, using for example the Android controller application to register with the Capability Service.
When receiving a capability request, the mobile phone will notify the user by for example ringing or vibrating.
As the user opens the request, he will now get a view detailing who asks for a capability, which service should be invoked and what the set of parameters is.
He now has two buttons to either accept or reject the request, causing the mobile phone to establish the requested session and forward it to the Capability Service if it was accepted.

But actually, human beings are just a special case of Registrants.
Instead of a human receiving requests, a special controller may connect to a Capability Service which is connected to some source for actual access control policies.
This controller will register and receive just the same as human Registrants would, but may automatically accept or reject requests based on the access control policy.

In theory, these automated controllers can be as simple or complex as one can imagine.
While a conventional user may have a controller allowing all his friends to connect to his home display, large enterprises could deploy controllers with distinguished policies based on information retrieved from Active Directory Domains Services.

One more possible use case is where a user owns a long-term signature key which is too important for him to have on his mobile phone in order to connect to certain services.
Instead, he may have a controller running at home with a Registrant connected owning the real long-term signature key.
The user may now establish a policy where the Registrant will always accept requests from his mobile phone, so he is able to have a different long-term signature key on his mobile phone and still always establish sessions with his real identity.

Currently, though, this specific use-case is a bit limited by the actual implementation, as the Registrant needs to be able to connect to the requested Service.
In many cases, as stated before, this may not work due to firewalls or inaccessibility of the Service from the Registrant's network.
To solve this problem, one can envision that the session establishment should be tunneled through the Capability Service, as well, instead of directly trying to connect to the Service.
The connection between Service and Registrant would obviously still be encrypted so the Capability Service is not able to listen on anything these services are talking.
In such a design, the Capability Service would completely proxy all traffic between Registrant, Client and Service without the Registrant talking to the Service or Client directly at all.

\subsubsection{Execution service}
\label{sec:exec-service}

The execution is a simple service providing some kind of shell to start up command line applications.
Upon connecting, the user specifies which executable to start, the parameters passed to the executable and the environment variables which should be set.

The server then starts the executable and forwards all output from \lstinline{stdout} and \lstinline{stderr} the client's channel as well as forwarding all input from the client's channel to \lstinline{stdin} of the executable.
As such clients starting the execution service are able to receive output of the program and provide input.

As this service is by default able to execute arbitrary command on the server, careful attention should be paid to the access policy.
That is, the server should not be made accessible by everybody but usually only by special users.

\subsubsection{Xpra service}
\label{sec:xpra-service}

The Xpra service wants to allow a client to forwards its graphical applications to a display connected to the Xpra service.
Given a set of graphical applications on the client starting the Xpra service, the Xpra service will connect to the Xpra instance running on the client encapsulating the applications and then display them on the attached display.

Xpra itself builds upon the X11 server technology and heavily uses X virtual frame buffers (Xvfb).
Xvfb is a technology where framebuffers are created which are not actually rendered to a display, but graphical applications are instead rendered into memory.
These virtual framebuffers can then be attached to by an Xpra client which will subsequently receive graphic updates and render these to the display.

Xpra was chosen as the display technology as it is very flexible in how it works.
Besides having cross-platform support for Windows, Linux and OS X, it is also capable of driving the communication between server and client with different encodings.
While it usually uses Portable Network Graphics (PNG) as encoding, it is also able to use the video codec H264 as encoding.
As such it is not only suitable to remotely display typical office desktops with text applications, but it is also able to stream graphically heavy applications like video players.

Xpra is built upon a server-client approach.
While the server owns the Xvfb where graphical applications are instantiated inside, the client attaches to the server and thus displays the actual graphics.
This gets particularly confusing to reason about combined with the Xpra service, which is hosted on the server but acts as the client to the Xvfb buffer.

The setup includes three involved entities:
\begin{description}
    \item[Xpra server]\hfill\\
        The Xpra server instance with the Xvfb where applications are rendered to.
        This Xpra server is usually instantiated on the Client side.
    \item[Client]\hfill\\
        The Client is the entity having a running Xpra server with a set of applications rendering to it.
        He wishes to display these applications on the Display service
    \item[Display service]\hfill\\
        The Display service is responsible for controlling the display and connecting to the Xpra server of the Client.
\end{description}

The following steps are required to display applications on the remote screen controlled by the Display service:
\begin{enumerate}
    \item The Client starts the Xpra server and (optionally) some applications running in the Xvfb
    \item The Client requests and starts a connection with the Display service
    \item The Display service starts up the Xpra client
    \item Data between Xpra server and Xpra client is tunneled through an encrypted channel
\end{enumerate}

The UML flow diagram in figure \ref{fig:xpra-service} details these steps.
The following functions are used:

\begin{description}
    \item[StartXpra($p$)]
        Start a new Xpra server instance on port $p$.
    \item[Request($i$) $\rightarrow$ $c$]
        Request a new session with no parameters for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
    \item[Forward($p$)]
        Forward data between port $p$ and the channel to the invoked entity.
    \item[ConnectXpra($p$)]
        Connect to a local Xpra instance on port $p$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newinst{x}{Xpra server}
        \newthread[2]{c}{Client $c$}
        \newinst[2]{s}{Display service}

        \begin{messcall}{c}{StartXpra($p_{xs}$)}{x}
            \postlevel

            \begin{call}{c}{Request($c$)}{s}{Capability $c$}
                \begin{call}{s}{CreateSession($c$, $c$, $p$)}{s}{Capability $c$}
                \end{call}
            \end{call}

            \postlevel

            \begin{messcall}{c}{Start($c$)}{s}
                \begin{call}{s}{StartXpraClient()}{s}{$p_{xc}$}
                \end{call}

                \begin{messcall}{s}{Forward($p_{xc}$)}{c}
                \end{messcall}
                \prelevel
                \begin{messcall}{c}{ConnectXpra($p_{xs}$)}{x}
                \end{messcall}

                \begin{messcall}{x}{Display data}{c}
                \end{messcall}
                \prelevel
                \prelevel
                \begin{messcall}{c}{Forward($p_{xs}$)}{s}
                \end{messcall}

            \prelevel
            \end{messcall}
            \prelevel
        \end{messcall}
    \end{sequencediagram}

    \caption{Xpra Service}
    \label{fig:xpra-service}
\end{figure}

Initially, the Client starts up a Xpra server with the applications.
The Xpra server will be bound to a local TCP port listening on the loopback interface only, so no other computers in the local network are able to connect to the Xpra server.

The Client establishes and connects to a new session with no parameters on the Display service.
Upon starting the session, the Display service creates a new Unix socket which will be put into listening mode, starts up the Xpra client and lets it connect to the newly created socket.
All traffic going through this socket will now be forwarded over the client channel and thus be encrypted.

As soon as initial data is arriving on the client's channel receiving side, he will open a new connection to the loopback interface on the port he has initially instructed the Xpra server to run on.
As soon as the Xpra server accepts the connection, he will forward data between the server channel and the Xpra server socket and thus finish the session setup.

\subsubsection{Synergy service}
\label{sec:synergy-service}

The Synergy service is an implementation of a mouse and keyboard sharing application.
It provides cross-platform support for Windows, Linux and OS X.

The service actually works nearly the same as the Xpra service and thus is not described in detail.
On client-side, the Synergy server is started which will handle capturing and forwarding mouse and keyboard input.
When the client starts a session with the Synergy service, the Synergy service starts up a Synergy client.
All data between the Synergy client and server will then be tunneled through the channel between client and server.

\medskip

What requires further though is the actual mode of input how it is set up in the end.
There are two possibilities on how to set it up: either input can be connected to the display server or it can be connected to the server hosting the actual application.

The most immediate concern is that of confidential input, e.g. when a user runs a confidential application on his server which then requires a password.
We will assume that the actual input device itself is safe to use and not tampered with as otherwise all considerations done on the software layer become naught.

As the user may not trust the environment where he is currently located, he might not want to connect his input devices to the display service, which would then forward traffic to the connected application.
Instead, he might want to send all input through the encrypted channel to his home server so that input is passed on directly to the application instead of first going through the Xpra service where keyloggers may be active.

Actually, assuming the Xpra service is being used for screen sharing, both modes are supported currently.
Input connected directly to the display's X server is currently able to modify displayed applications.
On the other hand, it is possible to connect input to the Xvfb in which applications are rendered directly, so that no additional redirection exists.
Unfortunately, Xpra is currently implemented such that the mouse cursor is not display so that a user cannot see the mouse cursor.

A workaround may be to split up mouse and keyboard input so that the mouse is connected to the display service and keyboard input is directly wired into the Xvfb.
While the mouse cursor would usually be visible anyway and thus should not provide any sensitive information to bystanders, the keyboard's input is often concealed when sensitive information is requested.
So the mouse will still be visible as it is directly connected to the display service and can be used to guide input of the keyboard around without revealing input data from the keyboard to third parties except the server executing the application.

Such a set up has not been tested though despite simple proof-of-concept tests with the Xvfb and input guidance.

\subsection{Development process}

The complete software stack is split up into two major components, namely the server-side part and the controller application for Android.
While these two components are strictly split up in functionality and dependencies, they still reside in a mono-repository so that it becomes easier to modify the core protocol and adjust both sides to work with the new version.

The server-side stack is written in the C programming language and currently clocks in at 6680 source lines of code excluding empty lines and comments.
Code is logically split up into a set of executables and libraries like following:
\begin{description}
    \item[Benchmarking]\hfill\\
        Two executables exist that drive the logic behind the benchmarks described in section \ref{sec:benchmarking}, where \emph{sd-bench} handles logic around throughput-benchmarks and \emph{sd-latency} estimates connection establishment latency.
    \item[Discovery]\hfill\\
        Service discovery is handled by \emph{sd-discovery-server} with a complementary executable \emph{sd-discover} used for testing the server implementation.
        It handles the process of directed and multicast server discovery as described in section \ref{sec:discovery}.
    \item[Server]\hfill\\
        The server executable \emph{sd-server} implements session management as well as handing off incoming connections to the requested service plug-ins.
        To drive the server from command line, another executable \emph{sd-client} has been written, that is able to query the server for details, request and start sessions.
    \item[Services]\hfill\\
        The services component contains the services implemented and described before in section \ref{sec:services}.
    \item[Library]\hfill\\
        Most functionality, most importantly the core protocol as well as the session handling, has been written such that it is contained in a single shared object with a documented interface.
        Like this it is easy to re-use logic in different executables or even in other projects.
        One more great benefit is that with a library-style interface, it is easy to drive unit tests on the library's interface.
    \item[Tests]\hfill\\
        Unit tests exist that cover much of the logic of the core library.
\end{description}

Table \ref{tab:sloc} summarizes the source lines of code per component, where the column ``Lines of source code'' counts the actual lines of code excluding comments and whitespace and the column ``Total lines'' counts the total amount of lines.
\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \bfseries Component & \bfseries Lines of source code & \bfseries Total lines\\
        \hline
        Benchmarking & 293 & 405\\
        \hline
        Discovery & 331 & 456\\
        \hline
        Server & 515 & 678\\
        \hline
        Services & 971 & 1523\\
        \hline
        Library & 2407 & 4798\\
        \hline
        Tests & 2075 & 2811 \\
        \hline
    \end{tabular}
    \caption{Lines of code per component for server}
    \label{tab:sloc}
\end{table}

A great emphasis has been put on cross-platform support.
As such, the code is written in strict ISO C90 \cite{iso-c90} which is supported by all modern compilers.
To guarantee that the code actually works on multiple platforms, multiple continuous integration (CI) services have been set up.
The CI services get notified on the event that a new commit has been pushed to a monitored repository and if so, they fetch the changes, build the applications and execute tests.
Currently, there are two CI services have been registered:
\begin{itemize}
    \item Travis CI \cite{travis} provides Linux and OS X build platforms
    \item AppVeyor \cite{appveyor} provides Windows build platforms
\end{itemize}

The project uses the Git source control management system \cite{git} and GitHub as its hosting platform \cite{github}.
In order to have a clean development process and a main branch which is always potentially releasable, that is it always builds and unit tests pass on all platforms, a development process is specified making heavy use of branches.
Every unit of development, e.g. a new feature, bugfixing or refactoring, is done in a separate branch which is then pushed to the main repository where it is picked up by the CI services.
As soon as all CI services have determined that the changes do not break the build on any platform and that all unit tests pass, the branch can be merged into the mainline.

As the C programming language requires manual resource management it is important to verify that the executables have no resource leaks and do not try to access resources that are not available anymore.
Most importantly, this involves checking for invalid memory dereferences, buffer overflows and memory leaks which are commonly used in attempts to exploit applications.

To work against this threat, special CI jobs exist which utilize the address and undefined behavior sanitizers of the GNU compiler collection (GCC) \cite{gcc}.
Executables compiled with these features enabled instrument the application in a specific way in order to analyze the application at run-time for invalid address references or for code relying on undefined behavior.
Like this, it is possible to catch programming errors related to referencing uninitialized memory, out-of-bounds array access, memory leaks and more.
The CI jobs execute the test suite with these flags enabled and report errors encountered during the execution.

One more service has been set up with Coverity Scan \cite{coverity}.
Code submitted to it will be analyzed at build time and submitted to the service, which then performs static analysis on source code level.
In contrast to the aforementioned CI services, Coverity Scan does not only analyze code which is actually executed while running the unit tests but covers the complete source code.
It is able to catch a lot of errors like invalid memory access and leaked file descriptors, but also catches other errors like time-of-check-time-of-use errors or problems related to multithreading.

\bigskip

The second component of the ecosystem is the controller application for Android mobile phones.
As the Android operating system provides a development environment based on the Dalvik Virtual Machine, the main programming language used to develop Android applications is the Java programming language.

As with the parts written in C, some effort has been done to have a clean separation between the protocol libraries and low-level functionality and the actual user interface.
The total controller application is around 2660 lines of actual code which can be split up into the following components:
\begin{description}
    \item[User interface]\hfill\\
        The user interface provides all functionality directly presented to the user.
        Core functionality currently provided by the application includes key management for the user's long term signature key, service discovery and favorites-management as well is the invocation of services.
    \item[Service plug-ins]\hfill\\
        Service plug-ins provide implementations for actual services which can be started.
        As of now, three service plug-ins have been implemented for the controller:
        \begin{itemize}
            \item a capability plug-in handling the relay of capabilities as described in \ref{sec:capability-service}
            \item an invoke plug-in causing a server to invoke another service chosen by the user as described in \ref{sec:invoke-service}
            \item an exec plug-in handling execution of programs on remote servers as described in \ref{sec:exec-service}
        \end{itemize}
    \item[Protocol]\hfill\\
        This module implements the protocol.
        This includes the low-level protocol used by channels as described in \ref{sec:low-level-protocol} and the messages exchanged for querying, session establishment and session invocation as described in section \ref{sec:protocol}.
\end{description}

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \bfseries Component & \bfseries Lines of source code & \bfseries Total lines\\
        \hline
        User interface & 968 & 1357\\
        \hline
        Service plug-ins & 711 & 1022\\
        \hline
        Protocol & 982 & 1513\\
        \hline
    \end{tabular}
    \caption{Lines of code per component for Android controller}
    \label{tab:sloc-controller}
\end{table}

Table \ref{tab:sloc-controller} provides an overview over the amount of code per component.

Due to timing constraints no tests are available for the Android application and no CI services have been set up.

% vim: ft=tex tw=0
