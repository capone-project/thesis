\section{Implementation}

\subsection{Services}
\label{sec:services}

Next to the protocol as it has been specified in section \ref{sec:architecture}, all functionality provided by the server is implemented in terms of services.
A service as such is a single unit providing usually providing a single functionality to users.

In order to start using service, the user first has to establish a service session and then subsequently start using the session (see section \ref{sec:session-initiation} for more details).
When establishing the service session, the user has to specify a set of parameters.
These parameters are passed on to the service when the created session is started by the user and may influence its behavior.
Assuming a shell service which provides the functionality to execute a program, the parameters may for example include which program to execute, what its parameters are and possibly environmental variables passed to the service.

There are currently five exemplary services implemented:
\begin{description}
    \item[Invoke service]\hfill\\
        Invoke services handle the use case where a user wants to execute a service on certain server hosting the invoke service.
        This is used heavily when the Android controller application is used, which will usually not execute provided services itself but instead cause another server (which provides the invoke service) to start the service.
    \item[Capability service]\hfill\\
        Capability services handle the use case where a user wants to ask another user for the permission to execute a service in his name.
    \item[Xpra service]\hfill\\
        Xpra is a specific implementation of an X11 server session manager.
        When applications are started in the Xpra server, it is possible to attach to this application on another computer and display the application on another screen.
    \item[Synergy service]\hfill\\
        Synergy handles forwarding of input devices, that is mouse and keyboard, to another computer.
    \item[Execution service]\hfill\\
        The execution service provides an interface to execute applications on a server.
\end{description}

We will now take a look at how these services actually work under the hood.

\subsubsection{Invoke service}
\label{sec:invoke-service}

The invoke service provides the ability to start a remote service on the server providing the invoke service.
There are up to three parties involved in the process:
\begin{description}
    \item[Controller]
        The entity controlling the process.
        The controller is the one directing the invoke service to invoke another service.
    \item[Invoker]
        The service providing the ability to start a service on the server it is hosted on.
    \item[Service]
        The service being started by the Invoker.
        While this service will often reside on another server than the invoke service, this is not a requirement.
\end{description}

References to these specific parties will be written with a capitalized first letter.
The whole process of service initiation has three steps:
\begin{enumerate}
    \item The Controller creates a new session with the Service that is to be started later by the Invoker.
    \item The Controller creates a new session with the Invoker, passing the capability for the session just created with the Service.
    \item The Controller starts the session created with the Invoker, causing the Invoker to start the session on the Service.
\end{enumerate}

These steps are visualized in an UML flow diagram in figure \ref{fig:invoke-service}.
Each entity has a public identity represented by the lowercase letter following its name.
The following functions are used in the diagram:
\begin{description}
    \item[Request($i$, $p$) $\rightarrow$ $c$]
        Request a new session with a set of parameters represented as key-value pairs for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newthread{c}{Client $c$}
        \newinst[3]{s}{Service $s$}
        \newinst[3]{i}{Invoker $i$}

        \begin{call}{c}{Request($i$, $p=\{\ldots\}$)}{s}{Capability $c_1$}
            \begin{call}{s}{CreateSession($c$, $i$, $p$)}{s}{Capability $c_1$}
            \end{call}
        \end{call}

        \postlevel

        \begin{call}{c}{Request($c$, $p=\{\text{service}=s, \text{cap}=c_1\}$)}{i}{Capability $c_2$}
            \begin{call}{i}{CreateSession($c$, $c$, $p$)}{i}{Capability $c_2$}
            \end{call}
        \end{call}
        \postlevel

        \begin{messcall}{c}{Start($c_1$)}{i}
            \postlevel
            \begin{messcall}{i}{Start($c_2$)}{s}
                \postlevel
            \end{messcall}
            \prelevel
        \end{messcall}
        \prelevel
    \end{sequencediagram}

    \caption{Invoke Service}
    \label{fig:invoke-service}
\end{figure}

On first sight, the order of session establishment may seem a bit puzzling, as the Service session is created before the Invoker session is being created.
But actually this results out of the protocol's design: no entity is able to create a session in in name of another entity when it does not know about the other entity's long term signature key.
As the Client wants to create a session which can be started by the Invoker, he will have to create a new capability which he owns but which the Invoker may use.

This use case is exactly why capabilities differentiate between their owners and their invokers:
the owner is the entity who creates the capability and who may destroy the capability before it has been used, but he is unable to use the capability.
The invoker of a capability is only able to use a capability which has been granted by either himself when creating a new session or which has been passed by another entity.

Returning back to the invoke service it now becomes obvious why the Client creates the session with the Service, as only he is able to create a session in his own name.
It would theoretically be possible for the Invoker to create the session himself, but assuming the Service has some kind of access control he might either not be allowed to create sessions or he may not be allowed to create sessions capable of accessing data belonging to Client.

All subsequent steps are now trivial:
Given the session just created, Service returns a capability which can be used by Invoker to the Client.
Client now creates a new session with Invoker, passing on the capability as well as specifying the address of the service that is to be invoked.

When the Invoker session has been created, Client starts it, causing the Invoker to retrieve the passed on capability for Service from the session parameters and connects to the session on Service.

\subsubsection{Capability service}
\label{sec:capability-service}

The capability service solves the use case wher an entity desires the ability to invoke a service in the name of another service.
That is it is the direct contrary to the invoke service, which can be used to push a capability to an invoker, in that the capability service pulls a capability from another entity.

Ideally, the capability service would not be required at all but instead, a requester would just directly ask another entity for permissions to execute a certain service.
But the requirement to directly connect to another entity requires the requester to always know of the address of the entity he wishes to ask.
As it may be very likely that the person asked for the capability uses a mobile phone with the Android application as a controller, the address might not be as stable as one would wish in this case.
Furthermore, it might be impossible to establish a direct connection when entities are in different networks, which usually use network address translation and do not allow direct connections to arbitrary ports.

In order to solve this problem, the capability service was developed as a means to forward capability requests between a requesting entity and a requested entity.
In fact the service does nothing more than allow entities to register themselves at the server and then subsequently forwards requests from other entities to registered entities and sending back capabilities created from accepted requests.
So it can be regarded as some kind of proxy service.

There are four participating entities which we will now define.
As before, we will subsequently refer to these entities by uppercasing the first letter.
\begin{description}
    \item[Client]\hfill\\
        The Client wishes to connect to the Service in the name of Registrant.
    \item[Registrant]\hfill\\
        The Registrant is an entity registered at the Capability Service.
        He is responsible for accepting or rejecting capability requests sent by Client.
    \item[Service]\hfill\\
        The Service is the service for which capabilities are requested for.
    \item[Capability Service]\hfill\\
        The Capability Service is a well-known service where entities may register to become Registrants or where capability requests are sent to by Clients in order to ask for permissions.
\end{description}

The process of capability requests involves five steps:
\begin{enumerate}
    \item The Registrant connects to the Capability Service
    \item The Client requests a capability from Registrant to invoke Service with a set of parameters by sending a request to Capability Service
    \item Capability Service forwards the request to Registrant
    \item Registrant decides if the request should be accepted or rejected.
        If it accepted, he creates a new session on Service for Client and send the capability to Capability Service
    \item Capability Service forwards the Capability to Client, who can now start the session on Service
\end{enumerate}

The whole process is visualized in figure \ref{fig:capability-request}.
The following functions are used in the diagram:
\begin{description}
    \item[Register()]\hfill\\
        Creates and starts a session with a Capability Service to become a registrant.
    \item[CapRequest($r$, $s$, $p$) $\rightarrow$ $c$]\hfill\\
        Request permissions to start service $s$ in the name of registrant $r$ with the set of parameters $p$.
        Returns a capability $c$ usable by the requester for service $s$.
    \item[Ask($c$, $s$, $p$) $\rightarrow$ $c$]\hfill\\
        Ask Registrant to create a capability for the client $c$ to invoke service $s$ with a set of parameters $p$.
        Returns a capability $c$ usable by the client $c$ if the registrant accepts the request.
    \item[Request($i$, $p$) $\rightarrow$ $c$]
        Request a new session with a set of parameters represented as key-value pairs for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newthread{c}{Client c}
        \newinst[1]{r}{Registrant r}
        \newinst[2]{s}{Service s}
        \newinst[2]{cap}{Capability Service}

        \mess{r}{Register}{cap}
        \postlevel

        \begin{call}{c}{CapRequest($r$, $s$, $p=\{\ldots\}$)}{cap}{Capability $c_1$}
            \postlevel
            \begin{call}{cap}{Ask($c$, $s$, $p$)}{r}{Capability $c_1$}
                \postlevel
                \begin{call}{r}{Request($c$, $p$)}{s}{Capability $c_1$}
                    \begin{call}{s}{CreateSession($r$, $c$, $p$)}{s}{Capability $c_1$}
                    \end{call}
                \end{call}
                \postlevel
            \end{call}
            \postlevel
        \end{call}

        \postlevel

        \begin{messcall}{c}{Start($c_1$)}{s}
            \postlevel
        \end{messcall}

        \prelevel
    \end{sequencediagram}

    \caption{Capability Request}
    \label{fig:capability-request}
\end{figure}

Let us now take a more detailed look at the steps.
The initial step is the registration of the Registrant.
The Capability Service needs to know where to send incoming capability requests to.
As such, entities who want to be able to answer capability requests need to register with the Capability Service in order to be able to retrieve the requests.

The registration is very simple in that a new session is created and opened with the Capability Service which, where the session is created as a \emph{Registrant} session.
Upon starting the session, the connection between Registrant and Capability Service will be kept alive and used to relay incoming requests.
Intuitively, one Capability Service can accept multiple Registrants at the same time.
For multiple Registrants with different identities the service works as one might expect:
Upon an incoming request, the Capability Service compares the requested identity with the identities of Registrants -- if one Registrant matches, the request will be forwarded to him.
Even though it is possible for the same entity to register twice at a Capability Service, this does not really make sense currently as the capability request is only forwarded to the first Registrant matching the entity requested by an incoming request.
This might change in future to either allow only one Registrant having the same identity at the same time or by forwarding the request to all matching Registrants, waiting for the first one to accept.

Independent of the registration, Clients may send capability requests to the server.
Each capability request contains whom to ask for permissions, which service the Client wants to have a capability for and a set of parameters which should be used to establish a session.
The request is sent to the Capability Service, which will now search its Registrants for one matching with the requested entity.
If one is found, the Capability Service will forward the capability request together with the entity of the Client asking for the capability to the matching Registrant.

As the Registrant receives the Capability Request, he will have to somehow determine if the requesting entity should be allowed to invoke the service as he requests or if the request should be rejected.
If he accepts the request, he will create a new session with Service for Client with the forwarded parameters, retrieves the newly created capability and forwards it to the Capability Service, which will subsequently forward the capability to the Client.
The Client is now able to use the capability to start a session with Service.

\medskip

The Registrant should be further explained now.
Often, the Registrant will be a human being, using for example the Android controller application to register with the Capability Service.
When receiving a capability request, the mobile phone will notify the user by for example ringing or vibrating.
As the user opens the request, he will now get a view detailing who asks for a capability, which service should be invoked and what the set of parameters is.
He now has two buttons to either accept or reject the request, causing the mobile phone to establish the requested session and forward it to the Capability Service if it was accepted.

But actually, human beings are just a special case of Registrants.
Instead of a human receiving requests, a special controller may connect to a Capability Service which is connected to some source for actual access control policies.
This controller will register and receive just the same as human Registrants would, but may automatically accept or reject requests based on the access control policy.

In theory, these automated controllers can be as simple or complex as one can imagine.
While a conventional user may have a controller allowing all his friends to connect to his home display, large enterprises could deploy controllers with distinguished policies based on information retrieved from Active Directory Domains Services.

One more possible use case is where a user owns a long-term signature key which is too important for him to have on his mobile phone in order to connect to certain services.
Instead, he may have a controller running at home with a Registrant connected owning the real long-term signature key.
The user may now establish a policy where the Registrant will always accept requests from his mobile phone, so he is able to have a different long-term signature key on his mobile phone and still always establish sessions with his real identity.

Currently, though, this specific use-case is a bit limited by the actual implementation, as the Registrant needs to be able to connect to the requested Service.
In many cases, as stated before, this may not work due to firewalls or inaccessibility of the Service from the Registrant's network.
To solve this problem, one can envision that the session establishment should be tunneled through the Capability Service, as well, instead of directly trying to connect to the Service.
The connection between Service and Registrant would obviously still be encrypted so the Capability Service is not able to listen on anything these services are talking.
In such a design, the Capability Service would completely proxy all traffic between Registrant, Client and Service withouth the Registrant talking to the Service or Client directly at all.

\subsubsection{Execution service}
\label{sec:exec-service}

The execution is a simple service providing some kind of shell to start up command line applications.
Upon connecting, the user specifies which executable to start, the parameters passed to the executable and the environment variables which should be set.

The server then starts the executable and forwards all output from \lstinline{stdout} and \lstinline{stderr} the client's channel as well as forwarding all input from the client's channel to \lstinline{stdin} of the executable.
As such clients starting the execution service are able to receive output of the program and provide input.

As this service is by default able to execute arbitrary command on the server, careful attention should be paid to the access policy.
That is, the server should not be made accessible by everybody but usually only by special users.

\subsubsection{Xpra service}
\label{sec:xpra-service}

\begin{figure}[H]
    \centering

    \begin{sequencediagram}
        \newinst{x}{Xpra server}
        \newthread[4]{c}{Client}
        \newinst[4]{s}{Display service}

        \begin{call}{c}{Start(port)}{x}{instance}
        \end{call}

        \postlevel

        \begin{messcall}{c}{InitiateConnection()}{s}
            \postlevel
            \begin{call}{c}{Request(xpra-port)}{s}{session}
            \end{call}
        \end{messcall}

        \postlevel

        \begin{messcall}{c}{InitiateConnection()}{s}
            \postlevel
            \begin{messcall}{c}{Connect(session)}{s}
            \end{messcall}

            \postlevel

            \begin{messcall}{s}{Tunneled data exchange}{x}
                \postlevel
            \end{messcall}
            \prelevel
            \prelevel
            \prelevel
            \begin{messcall}{x}{}{s}
            \end{messcall}
        \end{messcall}
    \end{sequencediagram}

    \caption{Xpra Service}
\end{figure}

\subsubsection{Synergy service}
\label{sec:synergy-service}

\subsection{Benchmarking}
\label{sec:benchmarking}

We will now provide measurements on how the project scales under different conditions.
There are three major measurements we are interested in and which directly influence the framework's usability.
\begin{description}
    \item[Throughput]\hfill\\
        How much data are we able to write through a channel in a certain amount of time.
        This statistics is of particular importance when performing bulk traffic, e.g. when connected to a file service or forwarding the user's desktop to a service.
    \item[Connection establishment]\hfill\\
        How long does it take to negotiate a connection with remote party.
        This is experienced by users which try to connect to a service and determines how long it will take until initial data is transferred between two entities.
    \item[Input latency]\hfill\\
        How long does it take until data submitted on either the user's or server's side arrives at the other party.
        This is of importance for interactive services like input forwarding.
\end{description}

We will test throughput and connection establishment with the low-level primitives used inside the framework.
Two small utilities (\lstinline{sd-bench} and \lstinline{sd-latency}) have been implemented to handle these and conduct the tests.
Both programs open a TCP server socket and then spawn a new thread which connects to the open socket.
They will then perform the actions specific to the benchmark.

Timings are obtained by invoking the POSIX function \lstinline{clock_gettime} with a monotonic clock.
Monotonic clocks do not jump in time when certain events happen on the system, e.g. when timezone changes or when \lstinline{adjtime} is called by some kind of NTP implementation.
On most systems, the \lstinline{clock_gettime} function provides timings in nanosecond resolution.

As timings are inherently inaccurate on computer systems due to interference with other programs, the kernel's scheduler, frequency scaling and more effects we are averaging the timing over repeated invocations of the core functionality that is to be benchmarked.
Experimentation showed results with errors in the range of $\pm2\%$.
This is precise enough in order to make observations as we usually operate in the range of multiple orders of magnitude where results are sufficiently distinct.

To increase reproducability on multi-core systems, both threads are fixed to a CPU core.
This tries to minimize scheduling problems and interference with other programs.

% TODO: describe latency framework

\medskip

All tests have been executed on a Linux 4.6.0 host with an Intel\textregistered Core\texttrademark i5-6600K with 6MB of of cache and a clock rate of 3.50GHz.
The benchmarking utilities and all dependencies have been compiled with GCC 5.3.0 with optimizations enabled.

\subsubsection{Throughput}

The throughput benchmark aims to measure how much data we can fit through a single connection to a remote host.
The primitive used for connections in our service stack is called a channel.
Channels encapsulate the low-level protocol of data streams, including the networking protocol (that is UDP or TCP) knowledge on how to split and re-assemble packages at their boundaries and how to encrypt or decrypt packages on encrypted connections (see section \ref{sec:low-level-protocol}).

As all protocols except the initial undirected service discovery use encrypted connections we will not benchmark unencrypted channels.
Furthermore, we will also ignore UDP-based channels as they are only used in the undirected service discovery, which does not require high throughput.

\medskip

We have to distinguish two different usage patterns when transmitting data.
The first pattern is transmitting many small messages between two parties.
This hapens a lot when transmitting control messages based on the protocol, which are usually in the range of a few bytes up to a maximum of a few hundred bytes, or for tunneled data for interactive services, e.g. input services.
The second pattern is when doing bulk data transfer for services, e.g. when transferring big files or when streaming videos.

Our goal is to maximize throughput for bulk transfers while keeping overhead low for small messages.
The factor directly influencing this is the message's block length.
As has been explained in the section on the low-level protocol (see section \ref{sec:low-level-protocol}, packages are split into chunks of a fixed amount of bytes by the transmitter and assembled to form the original message on the receiving side.
We have to tune the chunk sizes in order to optimize for throughput.

Unfortunately though it is not possible to tune for maximum throughput for small (in the range of up to a few hundreds of bytes) and big messages (starting at a few hundred of kilobytes) at the same time.
In order to optimize for small messages, we would ideally split messages into one chunk exactly big enough to fit in the complete message.
But let us assume we have optimized for a message length of 40 bytes.
As each transferred block has to contain a message authentication code of 16 bytes and that the initial message has to contain a message length of 4 bytes, the optimal block length would be 60 bytes (40 bytes $+$ 16 bytes $+$ 4 bytes $=$ 60 bytes).

When we now try to send a message of e.g. one megabyte (1024 $\cdot$ 1024 $=$ 1048576 bytes)  of data, it becomes obvious that the overhead added by the required metadata gets out of hand.
The following formula calculates the total required amount of bytes to send assuming a block length of 60 bytes.
Besides the total length of data to be transmitted, we need to send a message authentication code of 16 bytes for every block and an initial message length of 4 bytes:
\begin{align*}
    &\text{datalen} &+ &\text{blockcount} &* &\text{maclen} &+ &\text{messagelen} &= \text{total length}\\
    \Rightarrow &1048576 &+ & \lceil(1048576 / 40)\rceil &* &16 &+ &4\\
    \Rightarrow &1048576 &+ & 26215 &* &16 &+ &4\\
    \Rightarrow &1468020
\end{align*}
This amounts to an overhead of $40\%$ to transmit the data.
When tuning the block length to perform better for bulk transfers, the overhead would drastically decrease.
Take the following example where we assume a block length of 4 kilobytes (4096 bytes):
\begin{align*}
    &1048576 &+ &\lceil(1048576 / 4096)\rceil &* &16 &+ &4\\
    \Rightarrow &1048576 &+ &256 &* &16 &+ &4\\
    \Rightarrow &1052676
\end{align*}
The overhead decreased to a mere $0.4\%$.
So bulk transfers obviously have a big benefit when using big block sizes.

But we cannot simply set a huge block size and be done, as now smaller messages are penalized.
Given our initial assumption of a small message of 40 bytes of data and a block length of 4096 bytes, we now have an overhead of $4096 - 40 - 16 - 4 = 4038$ bytes, that is $98\%$ of the block are unused.
As network connections tend to be slow, especially when transferring data via an uplink through the internet, this will severely hamper performance for small messages.

But even for networks where sending data is cheap the overhead would bring down throughput as we have to honor that data is encrypted.
The more data we need to send the longer it takes to encrypt and decrypt the message on both sides.

\medskip

As we can see, we need to make a compromise between either achieving high throughput for small or large messages.
As such, we have to determine exactly how big the effects we just described are and how they affect throughput.
To do so, we implemented a simple throughput benchmarking utility which is comprised of two threads sending data to each other.
The utility transmits 1GB of data to the remote side, where data is split into messages of a user-defined size.
This procedure is repeated for block lengths between 64 and 4096 bytes.

To simulate different network conditions, we use the previously described mechanisms to target different network latencies.
We have chosen three different scenarios of 0ms of latency for transfer on the host itself, 2ms of latency for transfer to remote systems on the same local area network and 20ms of latency for transfer to remote systems in the wide area network.

To estimate the effect of block lengths for different scenarios, we have chosen to send messages of four different lengths with 256 bytes, 1 kilobyte, 100 kilobytes and 10 megabytes of data.
The results can be seen in figure \ref{fig:block-length-benchmarks} visualized as graphs.
See appendix \ref{sec:appendix-throughput} for bare results.

\begin{figure}
    \centering

    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=200,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{256 bytes of data}
        \label{fig:block-length-benchmark-256b}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=400,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{1 kilobyte of data}
        \label{fig:block-length-benchmark-1kb}
    \end{subfigure}

    \vspace{1em}

    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=750,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{100 kilobytes of data}
        \label{fig:block-length-benchmark-100kb}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=750,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{10 megabytes of data}
        \label{fig:block-length-benchmark-10mb}
    \end{subfigure}

    \caption{Sending data with different block lengths}
    \label{fig:block-length-benchmarks}
\end{figure}

The fours graphs display measurements for the different message sizes of 256 bytes, 1 kilobyte, 100 kilobytes and 10 megabytes.
Each of the figures has three different graphs representing the different scenarios for transfer of data on the same host and in LAN respectively WAN.
The x axis represents different block lengths in bytes used to split outgoing messages.
Please note that a logirithmic scale is used for block lengths.
The y axis represents the throughput achieved in megabytes per second averaged over the 1GB of data sent.
A higher value is better.

Additional constant dotted lines have been added to represent target throughput for ethernet (blue dashed line, 120MB/s) and internet (orange densely dotted line, 10MB/s).connections .
These aim to put an estimated maximum achievable throughput which aids at better comprehending the chosen block length.

\medskip

Let us first discuss graphs \ref{fig:block-length-benchmark-256b} and \ref{fig:block-length-benchmark-1kb} as examples for transferring small messages to a remote host.

What stands out is that there throughput caps out at block lengts of 512 bytes for 256 byte messages and at block lengths of 1500 bytes for 1024 byte messages, respectively.
The reason for this is obvious: these are the smallest block lengths where the whole message fits into.
Regard that for a message of length $l$, the smallest block length that is big enough to fit is $l + 16 + 4$.
With smaller block lengths we have to send multiple blocks to transmit the whole message and with bigger messages we have to encrypt additional padding.
So the optimal block length for small messages is the smallest one where the whole message with metadata fits into.

One more interesting thing to observe is that with increasing latency, throughput decreases and features of the graphs seem to diminish.
While the spike in throughput is easily visible on 0ms and 2ms of latency, it becomes barely recognizable on 20ms of latency.
The effect of feature-flattening seems to get even more obvious the more data is sent, but this is effect results from a different maximum throughput value.

Let us take a look at graphs \ref{fig:block-length-benchmark-100kb} and \ref{fig:block-length-benchmark-10mb} now for examples of bulk transfer.
The effect of latency on throughput is very interesting for these graphs - while throughput constantly increases when there is no latency at all, it caps out at 200MB/s for 2ms of latency and at 50MB/s for 20ms of latency.

For 2ms of latency the cap is at around a block length of 1500 bytes.
The value of 1500 was included in the benchmarks as this is a typical size of the maximum transmission unit (MTU) for ethernet connections.
The MTU is the size of the largest amount of data that can be sent in a single ethernet frame without requirement to split the frame into multiple frames.
With this information, we have a possible explanation as to why throuput caps out at around 1500 bytes and decreases afterwards for 2ms of latency, while it steadily increases for 0ms of latency.
Sending two frames with latency will obviously have an impact on throughput, while it does not have a real impact when there is no latency.

\medskip

These benchmarks do not pay attention to maximum bandwith available in LAN or WAN settings.
Usually, we cannot achieve more than around 100 megabytes per second in Gigabit Ethernet settings and around 10 megabytes per second in WAN settings.
We should honor this limitation when determining an optimal block length.

For small packages we are not able to reach the target throughput at for 2ms of latency and fail to meet the target starting at block lengths of 1024 for 20ms of latency when sending 256 byte messages.
For bulk transfer we start to hit the target in all scenarios when using a block length of 512 bytes.

\medskip

Let us subsume our findings from thesn benchmarks:
\begin{itemize}
    \item the optimum block length for short messages is the minimum block length able to fit in the complete message
    \item increasing block lengths will penalize short messages due to encryption overhead
    \item optimizing block length with high latencies is not useful due to throughput being near-flat
    \item optimal block length should not exceed length of the MTU (e.g. 1500 bytes)
\end{itemize}

To compromise between throughput for small and bulk traffic we chose a block length of 512 bytes.
It is the smallest block length able to achieve all target throughputs except for small messages with 2ms of latency, but we do not expect to need high throughput for small messages.

It may be desirable to make the block length configurable per service.
Services usually know their communication patterns and can thus optimize for the respective scenario they require.
Currently no such feature exists, but the block length is trivially changable at compile time and as such it would a small feat to make block lengths configurable at runtime.

\subsubsection{Connection latency}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[ylabel=Connection time (in ms),xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{0}] {data/latency.csv};
            \addlegendentry{0ms latency}

            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{2}] {data/latency.csv};
            \addlegendentry{2ms latency}

            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{20}] {data/latency.csv};
            \addlegendentry{20ms latency}
        \end{axis}
    \end{tikzpicture}
    \caption{Connection latency}
\end{figure}

\subsubsection{Input latency}

\subsection{Development process}

The complete software stack is split up into two major components, namely the server-side part and the controller application for Android.
While these two components are strictly split up in functionality and dependencies, they still reside in a mono-repository so that it becomes easier to modify the core protocol and adjust both sides to work with the new version.

The server-side stack is written in the C programming language and currently clocks in at 6680 source lines of code excluding empty lines and comments.
Code is logically split up into a set of executables and libraries like following:
\begin{description}
    \item[Benchmarking]\hfill\\
        Two executables exist that drive the logic behind the benchmarks described in section \ref{sec:benchmarking}, where \emph{sd-bench} handles logic around throughput-benchmarks and \emph{sd-latency} estimates connection establishment latency.
    \item[Discovery]\hfill\\
        Service discovery is handled by \emph{sd-discovery-server} with a complementary executable \emph{sd-discover} used for testing the server implementation.
        It handles the process of directed and multicast server discovery as described in section \ref{sec:discovery}.
    \item[Server]\hfill\\
        The server executable \emph{sd-server} implements session management as well as handing off incoming connections to the requested service plugins.
        To drive the server from command line, another executable \emph{sd-client} has been written, that is able to query the server for details, request and start sessions.
    \item[Services]\hfill\\
        The services component contains the services implemented and described before in section \ref{sec:services}.
    \item[Library]\hfill\\
        Most functionality, most importantly the core protocol as well as the session handling, has been written such that it is layed out in a single shared object with a documented interface.
        Like this it is easy to re-use logic in different executables or even in other projects.
        One more great benefit is that with a library-style interface, it is easy to drive unit tests on the library's interface.
    \item[Tests]\hfill\\
        Unit tests exist that cover much of the logic of the core library.
\end{description}

Table \ref{tab:sloc} summarizes the source lines of code per component, where the column ``Lines of source code'' counts the actual lines of code excluding comments and whitespace and the column ``Total lines'' counts the total amount of lines.
\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \bfseries Component & \bfseries Lines of source code & \bfseries Total lines\\
        \hline
        Benchmarking & 293 & 405\\
        \hline
        Discovery & 331 & 456\\
        \hline
        Server & 515 & 678\\
        \hline
        Services & 971 & 1523\\
        \hline
        Library & 2407 & 4798\\
        \hline
        Tests & 2075 & 2811 \\
        \hline
    \end{tabular}
    \caption{Lines of code per component for server}
    \label{tab:sloc}
\end{table}

A great emphasis has been put on cross-platform support.
As such, the code is written in strict ISO C90 \cite{iso-c90} which is supported by all modern compilers.
To guarantee that the code actually works on multiple platforms, multiple continuous integration (CI) services have been set up.
The CI services get notified on the event that a new commit has been pushed to a monitored repository and if so, they fetch the changes, build the applications and execute tests.
Currently, there are two CI services have been registered:
\begin{itemize}
    \item Travis CI \cite{travis} provides Linux and OS X build platforms
    \item AppVeyor \cite{appveyor} provides Windows build platforms
\end{itemize}

The project uses the Git source control management system \cite{git} and GitHub as its hosting platform \cite{github}.
In order to have a clean development process and a main branch which is always potentially releasable, that is it always builds and unit tests pass on all plattforms, a development process is specified making heavy use of branches.
Every unit of development, e.g. a new feature, bugfixing or refactoring, is done in a separate branch which is then pushed to the main repository where it is picked up by the CI services.
As soon as all CI services have determined that the changes do not break the build on any plattform and that all unit tests pass, the branch can be merged into the mainline.

As the C programming language requires manual resource management it is important to verify that the executables have no resource leaks and do not try to access resources that are not available anymore.
Most importantly, this involves checking for invalid memory dereferences, buffer overflows and memory leaks which are commonly used in attempts to exploit applciations.

To work against this threat, special CI jobs exist which utilize the address and undefined behavior sanitizers of the GNU compiler collection (GCC) \cite{gcc}.
Executables compiled with these features enabled instrument the application in a specific way in order to analyze the application at run-time for invalid address references or for code relying on undefined behavior.
Like this, it is possible to catch programming errors related to referencing uninitialized memory, out-of-bounds array access, memory leaks and more.
The CI jobs execute the test suite with these flags enabled and report errors encountered during the execution.

One more service has been set up with Coverity Scan \cite{coverity}.
Code submitted to it will be analyzed at build time and submitted to the service, which then performs static analysis on source code level.
In contrast to the aforementioned CI services, Coverity Scan does not only analyze code which is actually executed while running the unit tests but covers the complete source code.
It is able to catch a lot of errors like invalid memory access and leaked file descriptors, but also catches other errors like time-of-check-time-of-use errors or problems related to multithreading.

\bigskip

The second component of the ecosystem is the controller application for Android mobile phones.
As the Android operating system provides a development environment based on the Dalvik Virtual Machine, the main programming language used to develop Android applications is the Java programming language.

As with the parts written in C, some effort has been done to have a clean separation between the protocol libraries and low-level functionality and the actual user interface.
The total controller application is around 2660 lines of actual code which can be split up into the following components:
\begin{description}
    \item[User interface]\hfill\\
        The user interface provides all functionality directly presented to the user.
        Core functionality currently provided by the application includes key management for the user's long term signature key, service discovery and favorites-management as well is the invocation of services.
    \item[Service plugins]\hfill\\
        Service plugins provide implementations for actual services which can be started.
        As of now, three service plugins have been implemented for the controller:
        \begin{itemize}
            \item a capability plugin handling the relay of capabilities as described in \ref{sec:capability-service}
            \item an invoke plugin causing a server to invoke another service chosen by the user as described in \ref{sec:invoke-service}
            \item an exec plugin handling execution of programs on remote servers as described in \ref{sec:exec-service}
        \end{itemize}
    \item[Protocol]\hfill\\
        This module implements the protocol.
        This includes the low-level protocol used by channels as described in \ref{sec:low-level-protocol} and the messages exchanged for querying, session establishment and session invocation as described in section \ref{sec:protocol}.
\end{description}

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \bfseries Component & \bfseries Lines of source code & \bfseries Total lines\\
        \hline
        User interface & 968 & 1357\\
        \hline
        Service plugins & 711 & 1022\\
        \hline
        Protocol & 982 & 1513\\
        \hline
    \end{tabular}
    \caption{Lines of code per component for Android controller}
    \label{tab:sloc-controller}
\end{table}

Table \ref{tab:sloc-controller} provides an overview over the amount of code per component.

Due to timing constraints no tests are available for the Android application and no CI services have been set up.

% vim: ft=tex tw=0
