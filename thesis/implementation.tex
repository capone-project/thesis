\section{Implementation}

\subsection{Services}
\label{sec:services}

Next to the protocol as it has been specified in section \ref{sec:architecture}, all functionality provided by the server is implemented in terms of services.
A service as such is a single unit providing usually providing a single functionality to users.

In order to start using service, the user first has to establish a service session and then subsequently start using the session (see section \ref{sec:session-initiation} for more details).
When establishing the service session, the user has to specify a set of parameters.
These parameters are passed on to the service when the created session is started by the user and may influence its behavior.
Assuming a shell service which provides the functionality to execute a program, the parameters may for example include which program to execute, what its parameters are and possibly environmental variables passed to the service.

There are currently five exemplary services implemented:
\begin{description}
    \item[Invoke service]\hfill\\
        Invoke services handle the use case where a user wants to execute a service on certain server hosting the invoke service.
        This is used heavily when the Android controller application is used, which will usually not execute provided services itself but instead cause another server (which provides the invoke service) to start the service.
    \item[Capability service]\hfill\\
        Capability services handle the use case where a user wants to ask another user for the permission to execute a service in his name.
    \item[Xpra service]\hfill\\
        Xpra is a specific implementation of an X11 server session manager.
        When applications are started in the Xpra server, it is possible to attach to this application on another computer and display the application on another screen.
    \item[Synergy service]\hfill\\
        Synergy handles forwarding of input devices, that is mouse and keyboard, to another computer.
    \item[Execution service]\hfill\\
        The execution service provides an interface to execute applications on a server.
\end{description}

The current interface how service plugins are instantiated is very simple.
Each service has a set of functions to retrieve metadata on the service or to handle the connection to a server or from a client.
The aim of this design is to have services pluggable in the future, that is we want to have a true plugin-based approach.

Currently, all services are statically linked into the server's and client's executable.
But when a clean interface exists to separate each service from the main executable, we are later able to cut out these services and dynamically link them in as shared object later on, so that they can be linked on-demand.
This keeps the server lean in such a way that it only implements core functionality while still being extendable.

Being extendable and being able to only link to a certain set of service objects at runtime is of importance for cross-platform functionality.
Not every services may be available on all platform, e.g. when services link against the X server they might not easily be available on Windows.
In order to avoid having to handle all plugins conditionally of the build platform in the source code itself, we could easily extend the build system to build only a certain set of services.
In addition, it would become simpler for third-party developers to create and tie in additional services.

\medskip

To guarantee a working plugin system we have to have a working plugin-interface, though.
The current service interface consists of the following functions:
\begin{itemize}
    \item An init function initializing the plugin
    \item A function reporting the service's version
    \item A function reporting parameters the service may be invoked with
    \item A handler function which handles the server side of a session
    \item An invoke function which handles the client side of a session
\end{itemize}

The heart of each plugin is contained in the \lstinline{handler} and \lstinline{invoke} functions.
When a client wants to execute a service and the service session has been started, the client's executable will execute the \lstinline{invoke} function of the service plugin, receiving the channel and the client's configuration as arguments.
It will then perform all service-specific actions and communicate with the remote side via the channel, which transparently handles encryption.

The \lstinline{handle} function is the counterpart to \lstinline{invoke}.
Upon a client connecting to a server and starting a session, the server will execute \lstinline{handle} for the respective plugin, passing in the session with its parameters as well as the channel connected to the client.

It remains to be seen if this interface design is sufficient to handle different use-cases required by different service plugins.

\subsubsection{Invoke service}
\label{sec:invoke-service}

The invoke service provides the ability to start a remote service on the server providing the invoke service.
There are up to three parties involved in the process:
\begin{description}
    \item[Controller]
        The entity controlling the process.
        The controller is the one directing the invoke service to invoke another service.
    \item[Invoker]
        The service providing the ability to start a service on the server it is hosted on.
    \item[Service]
        The service being started by the Invoker.
        While this service will often reside on another server than the invoke service, this is not a requirement.
\end{description}

References to these specific parties will be written with a capitalized first letter.
The whole process of service initiation has three steps:
\begin{enumerate}
    \item The Controller creates a new session with the Service that is to be started later by the Invoker.
    \item The Controller creates a new session with the Invoker, passing the capability for the session just created with the Service.
    \item The Controller starts the session created with the Invoker, causing the Invoker to start the session on the Service.
\end{enumerate}

These steps are visualized in an UML flow diagram in figure \ref{fig:invoke-service}.
Each entity has a public identity represented by the lowercase letter following its name.
The following functions are used in the diagram:
\begin{description}
    \item[Request($i$, $p$) $\rightarrow$ $c$]
        Request a new session with a set of parameters represented as key-value pairs for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newthread{c}{Client $c$}
        \newinst[3]{s}{Service $s$}
        \newinst[3]{i}{Invoker $i$}

        \begin{call}{c}{Request($i$, $p=\{\ldots\}$)}{s}{Capability $c_1$}
            \begin{call}{s}{CreateSession($c$, $i$, $p$)}{s}{Capability $c_1$}
            \end{call}
        \end{call}

        \postlevel

        \begin{call}{c}{Request($c$, $p=\{\text{service}=s, \text{cap}=c_1\}$)}{i}{Capability $c_2$}
            \begin{call}{i}{CreateSession($c$, $c$, $p$)}{i}{Capability $c_2$}
            \end{call}
        \end{call}
        \postlevel

        \begin{messcall}{c}{Start($c_1$)}{i}
            \postlevel
            \begin{messcall}{i}{Start($c_2$)}{s}
                \postlevel
            \end{messcall}
            \prelevel
        \end{messcall}
        \prelevel
    \end{sequencediagram}

    \caption{Invoke Service}
    \label{fig:invoke-service}
\end{figure}

On first sight, the order of session establishment may seem a bit puzzling, as the Service session is created before the Invoker session is being created.
But actually this results out of the protocol's design: no entity is able to create a session in name of another entity when it does not know about the other entity's long term signature key.
As the Client wants to create a session which can be started by the Invoker, he will have to create a new capability which he owns but which the Invoker may use.

This use case is exactly why capabilities differentiate between their owners and their invokers:
the owner is the entity who creates the capability and who may destroy the capability before it has been used, but he is unable to use the capability.
The invoker of a capability is only able to use a capability which has been granted by either himself when creating a new session or which has been passed by another entity.

Returning back to the invoke service it now becomes obvious why the Client creates the session with the Service, as only he is able to create a session in his own name.
It would theoretically be possible for the Invoker to create the session himself, but assuming the Service has some kind of access control he might either not be allowed to create sessions or he may not be allowed to create sessions capable of accessing data belonging to Client.

All subsequent steps are now trivial:
Given the session just created, Service returns a capability which can be used by Invoker to the Client.
Client now creates a new session with Invoker, passing on the capability as well as specifying the address of the service that is to be invoked.

When the Invoker session has been created, Client starts it, causing the Invoker to retrieve the passed on capability for Service from the session parameters and connects to the session on Service.

\subsubsection{Capability service}
\label{sec:capability-service}

The capability service solves the use case where an entity desires the ability to invoke a service in the name of another service.
That is it is the direct contrary to the invoke service, which can be used to push a capability to an invoker, in that the capability service pulls a capability from another entity.

Ideally, the capability service would not be required at all but instead, a requester would just directly ask another entity for permissions to execute a certain service.
But the requirement to directly connect to another entity requires the requester to always know of the address of the entity he wishes to ask.
As it may be very likely that the person asked for the capability uses a mobile phone with the Android application as a controller, the address might not be as stable as one would wish in this case.
Furthermore, it might be impossible to establish a direct connection when entities are in different networks, which usually use network address translation and do not allow direct connections to arbitrary ports.

In order to solve this problem, the capability service was developed as a means to forward capability requests between a requesting entity and a requested entity.
In fact the service does nothing more than allow entities to register themselves at the server and then subsequently forwards requests from other entities to registered entities and sending back capabilities created from accepted requests.
So it can be regarded as some kind of proxy service.

There are four participating entities which we will now define.
As before, we will subsequently refer to these entities by upper-casing the first letter.
\begin{description}
    \item[Client]\hfill\\
        The Client wishes to connect to the Service in the name of Registrant.
    \item[Registrant]\hfill\\
        The Registrant is an entity registered at the Capability Service.
        He is responsible for accepting or rejecting capability requests sent by Client.
    \item[Service]\hfill\\
        The Service is the service for which capabilities are requested for.
    \item[Capability Service]\hfill\\
        The Capability Service is a well-known service where entities may register to become Registrants or where capability requests are sent to by Clients in order to ask for permissions.
\end{description}

The process of capability requests involves five steps:
\begin{enumerate}
    \item The Registrant connects to the Capability Service
    \item The Client requests a capability from Registrant to invoke Service with a set of parameters by sending a request to Capability Service
    \item Capability Service forwards the request to Registrant
    \item Registrant decides if the request should be accepted or rejected.
        If it accepted, he creates a new session on Service for Client and send the capability to Capability Service
    \item Capability Service forwards the Capability to Client, who can now start the session on Service
\end{enumerate}

The whole process is visualized in figure \ref{fig:capability-request}.
The following functions are used in the diagram:
\begin{description}
    \item[Register()]\hfill\\
        Creates and starts a session with a Capability Service to become a registrant.
    \item[CapRequest($r$, $s$, $p$) $\rightarrow$ $c$]\hfill\\
        Request permissions to start service $s$ in the name of registrant $r$ with the set of parameters $p$.
        Returns a capability $c$ usable by the requester for service $s$.
    \item[Ask($c$, $s$, $p$) $\rightarrow$ $c$]\hfill\\
        Ask Registrant to create a capability for the client $c$ to invoke service $s$ with a set of parameters $p$.
        Returns a capability $c$ usable by the client $c$ if the registrant accepts the request.
    \item[Request($i$, $p$) $\rightarrow$ $c$]
        Request a new session with a set of parameters represented as key-value pairs for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newthread{c}{Client c}
        \newinst[1]{r}{Registrant r}
        \newinst[2]{s}{Service s}
        \newinst[2]{cap}{Capability Service}

        \mess{r}{Register}{cap}
        \postlevel

        \begin{call}{c}{CapRequest($r$, $s$, $p=\{\ldots\}$)}{cap}{Capability $c_1$}
            \postlevel
            \begin{call}{cap}{Ask($c$, $s$, $p$)}{r}{Capability $c_1$}
                \postlevel
                \begin{call}{r}{Request($c$, $p$)}{s}{Capability $c_1$}
                    \begin{call}{s}{CreateSession($r$, $c$, $p$)}{s}{Capability $c_1$}
                    \end{call}
                \end{call}
                \postlevel
            \end{call}
            \postlevel
        \end{call}

        \postlevel

        \begin{messcall}{c}{Start($c_1$)}{s}
            \postlevel
        \end{messcall}

        \prelevel
    \end{sequencediagram}

    \caption{Capability Request}
    \label{fig:capability-request}
\end{figure}

Let us now take a more detailed look at the steps.
The initial step is the registration of the Registrant.
The Capability Service needs to know where to send incoming capability requests to.
As such, entities who want to be able to answer capability requests need to register with the Capability Service in order to be able to retrieve the requests.

The registration is very simple in that a new session is created and opened with the Capability Service which, where the session is created as a \emph{Registrant} session.
Upon starting the session, the connection between Registrant and Capability Service will be kept alive and used to relay incoming requests.
Intuitively, one Capability Service can accept multiple Registrants at the same time.
For multiple Registrants with different identities the service works as one might expect:
Upon an incoming request, the Capability Service compares the requested identity with the identities of Registrants -- if one Registrant matches, the request will be forwarded to him.
Even though it is possible for the same entity to register twice at a Capability Service, this does not really make sense currently as the capability request is only forwarded to the first Registrant matching the entity requested by an incoming request.
This might change in future to either allow only one Registrant having the same identity at the same time or by forwarding the request to all matching Registrants, waiting for the first one to accept.

Independent of the registration, Clients may send capability requests to the server.
Each capability request contains whom to ask for permissions, which service the Client wants to have a capability for and a set of parameters which should be used to establish a session.
The request is sent to the Capability Service, which will now search its Registrants for one matching with the requested entity.
If one is found, the Capability Service will forward the capability request together with the entity of the Client asking for the capability to the matching Registrant.

As the Registrant receives the Capability Request, he will have to somehow determine if the requesting entity should be allowed to invoke the service as he requests or if the request should be rejected.
If he accepts the request, he will create a new session with Service for Client with the forwarded parameters, retrieves the newly created capability and forwards it to the Capability Service, which will subsequently forward the capability to the Client.
The Client is now able to use the capability to start a session with Service.

\medskip

The Registrant should be further explained now.
Often, the Registrant will be a human being, using for example the Android controller application to register with the Capability Service.
When receiving a capability request, the mobile phone will notify the user by for example ringing or vibrating.
As the user opens the request, he will now get a view detailing who asks for a capability, which service should be invoked and what the set of parameters is.
He now has two buttons to either accept or reject the request, causing the mobile phone to establish the requested session and forward it to the Capability Service if it was accepted.

But actually, human beings are just a special case of Registrants.
Instead of a human receiving requests, a special controller may connect to a Capability Service which is connected to some source for actual access control policies.
This controller will register and receive just the same as human Registrants would, but may automatically accept or reject requests based on the access control policy.

In theory, these automated controllers can be as simple or complex as one can imagine.
While a conventional user may have a controller allowing all his friends to connect to his home display, large enterprises could deploy controllers with distinguished policies based on information retrieved from Active Directory Domains Services.

One more possible use case is where a user owns a long-term signature key which is too important for him to have on his mobile phone in order to connect to certain services.
Instead, he may have a controller running at home with a Registrant connected owning the real long-term signature key.
The user may now establish a policy where the Registrant will always accept requests from his mobile phone, so he is able to have a different long-term signature key on his mobile phone and still always establish sessions with his real identity.

Currently, though, this specific use-case is a bit limited by the actual implementation, as the Registrant needs to be able to connect to the requested Service.
In many cases, as stated before, this may not work due to firewalls or inaccessibility of the Service from the Registrant's network.
To solve this problem, one can envision that the session establishment should be tunneled through the Capability Service, as well, instead of directly trying to connect to the Service.
The connection between Service and Registrant would obviously still be encrypted so the Capability Service is not able to listen on anything these services are talking.
In such a design, the Capability Service would completely proxy all traffic between Registrant, Client and Service without the Registrant talking to the Service or Client directly at all.

\subsubsection{Execution service}
\label{sec:exec-service}

The execution is a simple service providing some kind of shell to start up command line applications.
Upon connecting, the user specifies which executable to start, the parameters passed to the executable and the environment variables which should be set.

The server then starts the executable and forwards all output from \lstinline{stdout} and \lstinline{stderr} the client's channel as well as forwarding all input from the client's channel to \lstinline{stdin} of the executable.
As such clients starting the execution service are able to receive output of the program and provide input.

As this service is by default able to execute arbitrary command on the server, careful attention should be paid to the access policy.
That is, the server should not be made accessible by everybody but usually only by special users.

\subsubsection{Xpra service}
\label{sec:xpra-service}

The Xpra service wants to allow a client to forwards its graphical applications to a display connected to the Xpra service.
Given a set of graphical applications on the client starting the Xpra service, the Xpra service will connect to the Xpra instance running on the client encapsulating the applications and then display them on the attached display.

Xpra itself builds upon the X11 server technology and heavily uses X virtual frame buffers (Xvfb).
Xvfb is a technology where framebuffers are created which are not actually rendered to a display, but graphical applications are instead rendered into memory.
These virtual framebuffers can then be attached to by an Xpra client which will subsequently receive graphic updates and render these to the display.

Xpra was chosen as the display technology as it is very flexible in how it works.
Besides having cross-platform support for Windows, Linux and OS X, it is also capable of driving the communication between server and client with different encodings.
While it usually uses Portable Network Graphics (PNG) as encoding, it is also able to use the video codec H264 as encoding.
As such it is not only suitable to remotely display typical office desktops with text applications, but it is also able to stream graphically heavy applications like video players.

Xpra is built upon a server-client approach.
While the server owns the Xvfb where graphical applications are instantiated inside, the client attaches to the server and thus displays the actual graphics.
This gets particularly confusing to reason about combined with the Xpra service, which is hosted on the server but acts as the client to the Xvfb buffer.

The setup includes three involved entities:
\begin{description}
    \item[Xpra server]\hfill\\
        The Xpra server instance with the Xvfb where applications are rendered to.
        This Xpra server is usually instantiated on the Client side.
    \item[Client]\hfill\\
        The Client is the entity having a running Xpra server with a set of applications rendering to it.
        He wishes to display these applications on the Display service
    \item[Display service]\hfill\\
        The Display service is responsible for controlling the display and connecting to the Xpra server of the Client.
\end{description}

The following steps are required to display applications on the remote screen controlled by the Display service:
\begin{enumerate}
    \item The Client starts the Xpra server and (optionally) some applications running in the Xvfb
    \item The Client requests and starts a connection with the Display service
    \item The Display service starts up the Xpra client
    \item Data between Xpra server and Xpra client is tunneled through an encrypted channel
\end{enumerate}

The UML flow diagram in figure \ref{fig:xpra-service} details these steps.
The following functions are used:

\begin{description}
    \item[StartXpra($p$)]
        Start a new Xpra server instance on port $p$.
    \item[Request($i$) $\rightarrow$ $c$]
        Request a new session with no parameters for entity $i$.
        Returns a capability $c$ which can be used by $i$.
    \item[CreateSession($e$, $i$, $p$) $\rightarrow$ $c$]
        Create a new session with session owner $e$ for invocation by entity $i$, storing the set of parameters $p$.
        Returns a capability $c$ used to invoke the session.
    \item[Start($c$)]
        Start the session associated with capability $c$.
    \item[Forward($p$)]
        Forward data between port $p$ and the channel to the invoked entity.
    \item[ConnectXpra($p$)]
        Connect to a local Xpra instance on port $p$.
\end{description}

\begin{figure}[t]
    \centering

    \begin{sequencediagram}
        \newinst{x}{Xpra server}
        \newthread[2]{c}{Client $c$}
        \newinst[2]{s}{Display service}

        \begin{messcall}{c}{StartXpra($p_{xs}$)}{x}
            \postlevel

            \begin{call}{c}{Request($c$)}{s}{Capability $c$}
                \begin{call}{s}{CreateSession($c$, $c$, $p$)}{s}{Capability $c$}
                \end{call}
            \end{call}

            \postlevel

            \begin{messcall}{c}{Start($c$)}{s}
                \begin{call}{s}{StartXpraClient()}{s}{$p_{xc}$}
                \end{call}

                \begin{messcall}{s}{Forward($p_{xc}$)}{c}
                \end{messcall}
                \prelevel
                \begin{messcall}{c}{ConnectXpra($p_{xs}$)}{x}
                \end{messcall}

                \begin{messcall}{x}{Display data}{c}
                \end{messcall}
                \prelevel
                \prelevel
                \begin{messcall}{c}{Forward($p_{xs}$)}{s}
                \end{messcall}

            \prelevel
            \end{messcall}
            \prelevel
        \end{messcall}
    \end{sequencediagram}

    \caption{Xpra Service}
    \label{fig:xpra-service}
\end{figure}

Initially, the Client starts up a Xpra server with the applications.
The Xpra server will be bound to a local TCP port listening on the loopback interface only, so no other computers in the local network are able to connect to the Xpra server.

The Client establishes and connects to a new session with no parameters on the Display service.
Upon starting the session, the Display service creates a new Unix socket which will be put into listening mode, starts up the Xpra client and lets it connect to the newly created socket.
All traffic going through this socket will now be forwarded over the client channel and thus be encrypted.

As soon as initial data is arriving on the client's channel receiving side, he will open a new connection to the loopback interface on the port he has initially instructed the Xpra server to run on.
As soon as the Xpra server accepts the connection, he will forward data between the server channel and the Xpra server socket and thus finish the session setup.

\subsubsection{Synergy service}
\label{sec:synergy-service}

The Synergy service is an implementation of a mouse and keyboard sharing application.
It provides cross-platform support for Windows, Linux and OS X.

The service actually works nearly the same as the Xpra service and thus is not described in detail.
On client-side, the Synergy server is started which will handle capturing and forwarding mouse and keyboard input.
When the client starts a session with the Synergy service, the Synergy service starts up a Synergy client.
All data between the Synergy client and server will then be tunneled through the channel between client and server.

\medskip

What requires further though is the actual mode of input how it is set up in the end.
There are two possibilities on how to set it up: either input can be connected to the display server or it can be connected to the server hosting the actual application.

The most immediate concern is that of confidential input, e.g. when a user runs a confidential application on his server which then requires a password.
We will assume that the actual input device itself is safe to use and not tampered with as otherwise all considerations done on the software layer become naught.

As the user may not trust the environment where he is currently located, he might not want to connect his input devices to the display service, which would then forward traffic to the connected application.
Instead, he might want to send all input through the encrypted channel to his home server so that input is passed on directly to the application instead of first going through the Xpra service where keyloggers may be active.

Actually, assuming the Xpra service is being used for screen sharing, both modes are supported currently.
Input connected directly to the display's X server is currently able to modify displayed applications.
On the other hand, it is possible to connect input to the Xvfb in which applications are rendered directly, so that no additional redirection exists.
Unfortunately, Xpra is currently implemented such that the mouse cursor is not display so that a user cannot see the mouse cursor.

A workaround may be to split up mouse and keyboard input so that the mouse is connected to the display service and keyboard input is directly wired into the Xvfb.
While the mouse cursor would usually be visible anyway and thus should not provide any sensitive information to bystanders, the keyboard's input is often concealed when sensitive information is requested.
So the mouse will still be visible as it is directly connected to the display service and can be used to guide input of the keyboard around without revealing input data from the keyboard to third parties except the server executing the application.

Such a set up has not been tested though despite simple proof-of-concept tests with the Xvfb and input guidance.

\subsection{Benchmarking}
\label{sec:benchmarking}

We will now provide measurements on how the project scales under different conditions.
There are three major measurements we are interested in and which directly influence the framework's usability.
\begin{description}
    \item[Throughput]\hfill\\
        How much data are we able to write through a channel in a certain amount of time.
        This statistics is of particular importance when performing bulk traffic, e.g. when connected to a file service or forwarding the user's desktop to a service.
    \item[Connection establishment]\hfill\\
        How long does it take to negotiate a connection with remote party.
        This is experienced by users which try to connect to a service and determines how long it will take until initial data is transferred between two entities.
    \item[Input latency]\hfill\\
        How long does it take until data submitted on either the user's or server's side arrives at the other party.
        This is of importance for interactive services like input forwarding.
\end{description}

We will test throughput and connection establishment with the low-level primitives used inside the framework.
Two small utilities (\lstinline{sd-bench} and \lstinline{sd-latency}) have been implemented to handle these and conduct the tests.
Both programs open a TCP server socket and then spawn a new thread which connects to the open socket.
They will then perform the actions specific to the benchmark.

Timings are obtained by invoking the POSIX function \lstinline{clock_gettime} with a monotonic clock.
Monotonic clocks do not jump in time when certain events happen on the system, e.g. when timezone changes or when \lstinline{adjtime} is called by some kind of NTP implementation.
On most systems, the \lstinline{clock_gettime} function provides timings in nanosecond resolution.

As timings are inherently inaccurate on computer systems due to interference with other programs, the kernel's scheduler, frequency scaling and more effects we are averaging the timing over repeated invocations of the core functionality that is to be benchmarked.
Experimentation showed results with errors in the range of $\pm2\%$.
This is precise enough in order to make observations as we usually operate in the range of multiple orders of magnitude where results are sufficiently distinct.

To increase reproducability on multi-core systems, both threads are fixed to a CPU core.
This tries to minimize scheduling problems and interference with other programs.

\medskip

All benchmarks were done with three different network settings in mind to actually show how the framework behaves in different use cases.
These three settings involve same-host, local network and usage via the internet.

How networks perform is dependent on various parameters.
The most important ones include bandwidth, packet delay, packet loss, packet duplication and packet reordering.
These factors together determine how well networks perform under different loads.

Packet loss, duplication and reordering are not tested in any benchmark as all operations except device discovery are done via the Transmission Control Protocol (TCP).
The TCP stack already handles all these conditions transparently, so by testing these parameters we would in fact be benchmarking how well the TCP protocol behaves.
Another reason is that these parameters can only be emulated via statistical distributions.
In order to have reproducible results, we would have to greatly increase the scope of how long the framework is benchmarked to average out the effects of each of these parameters.

Bandwidth is not respected, as well.
For the throughput benchmark, we obviously do not want to limit the available bandwidth as we want to determine how much data we are able to process in a fixed amount of time and as such cannot restrict available bandwidth.
The other two tests on connection establishment and input latency are not limited by bandwidth and as such it would be of no use to consider bandwidth in here and thus complicate the benchmarking setup.

The last parameter remaining is packet delay, that is how long does it take for a packet emitted from one host to arrive at another host.
The different network scenarios all have different package delay characteristics.
While same-host communication should be near-instant, that is all data sent is only delayed by the time the operating system requires to process data in the TCP/IP stack and by the framework, local area networks and the internet both induce a delay.
For local area networks, which we define as computers which are connected to the same router via network cables in this context, we have chosen a packet delay of 2 milliseconds.
For internet-based connections, we have chosen a packet delay of 20 milliseconds.

Obviously, these delays are somewhat arbitrary as different networks have different latency.
Especially on connections via the internet, the delay can vary greatly based on location of both parties, quality of service and other factors.
But as benchmarking results will show, these fixed delays are already able to show patterns in how the framework behaves.

In order to test these different conditions the network emulation framework NetEm, which is part of the Linux kernel, has been utilized \cite{hemminger2005network}.
NetEm is a framework developed by Hemminger in 2005 in order to benchmark applications under different networking conditions.
It provides the means to modify how the traffic control engine in the Linux kernel behaves by providing the ability to put artificial packet delays, packet drops and more characteristics on single networking interfaces.

In order to execute following benchmarks, all benchmarks connect via the loopback interface to a counterpart on the same host.
The loopback interface has then been prepared to handle a certain scenario by putting a delay of 0, 2 or 20 milliseconds on the loopback interface.
Like this, the tests become reproducible by not being reliant on external networking conditions and can be re-executed an arbitrary amount of time.

\medskip

All tests have been executed on a Linux 4.6.0 host with an Intel\textregistered Core\texttrademark i5-6600K with 6MB of cache and a clock rate of 3.50GHz.
The benchmarking utilities and all dependencies have been compiled with GCC 5.3.0 with optimizations enabled.

\subsubsection{Throughput}

The throughput benchmark aims to measure how much data we can fit through a single connection to a remote host.
The primitive used for connections in our service stack is called a channel.
Channels encapsulate the low-level protocol of data streams, including the networking protocol (that is UDP or TCP) knowledge on how to split and re-assemble packages at their boundaries and how to encrypt or decrypt packages on encrypted connections (see section \ref{sec:low-level-protocol}).

As all protocols except the initial undirected service discovery use encrypted connections we will not benchmark unencrypted channels.
Furthermore, we will also ignore UDP-based channels as they are only used in the undirected service discovery, which does not require high throughput.

\medskip

We have to distinguish two different usage patterns when transmitting data.
The first pattern is transmitting many small messages between two parties.
This happens a lot when transmitting control messages based on the protocol, which are usually in the range of a few bytes up to a maximum of a few hundred bytes, or for tunneled data for interactive services, e.g. input services.
The second pattern is when doing bulk data transfer for services, e.g. when transferring big files or when streaming videos.

Our goal is to maximize throughput for bulk transfers while keeping overhead low for small messages.
The factor directly influencing this is the message's block length.
As has been explained in the section on the low-level protocol (see section \ref{sec:low-level-protocol}, packages are split into chunks of a fixed amount of bytes by the transmitter and assembled to form the original message on the receiving side.
We have to tune the chunk sizes in order to optimize for throughput.

Unfortunately though it is not possible to tune for maximum throughput for small (in the range of up to a few hundreds of bytes) and big messages (starting at a few hundred of kilobytes) at the same time.
In order to optimize for small messages, we would ideally split messages into one chunk exactly big enough to fit in the complete message.
But let us assume we have optimized for a message length of 40 bytes.
As each transferred block has to contain a message authentication code of 16 bytes and that the initial message has to contain a message length of 4 bytes, the optimal block length would be 60 bytes (40 bytes $+$ 16 bytes $+$ 4 bytes $=$ 60 bytes).

When we now try to send a message of e.g. one megabyte (1024 $\cdot$ 1024 $=$ 1048576 bytes)  of data, it becomes obvious that the overhead added by the required metadata gets out of hand.
The following formula calculates the total required amount of bytes to send assuming a block length of 60 bytes.
Besides the total length of data to be transmitted, we need to send a message authentication code of 16 bytes for every block and an initial message length of 4 bytes:
\begin{align*}
    &\text{datalen} &+ &\text{blockcount} &* &\text{maclen} &+ &\text{messagelen} &= \text{total length}\\
    \Rightarrow &1048576 &+ & \lceil(1048576 / 40)\rceil &* &16 &+ &4\\
    \Rightarrow &1048576 &+ & 26215 &* &16 &+ &4\\
    \Rightarrow &1468020
\end{align*}
This amounts to an overhead of $40\%$ to transmit the data.
When tuning the block length to perform better for bulk transfers, the overhead would drastically decrease.
Take the following example where we assume a block length of 4 kilobytes (4096 bytes):
\begin{align*}
    &1048576 &+ &\lceil(1048576 / 4096)\rceil &* &16 &+ &4\\
    \Rightarrow &1048576 &+ &256 &* &16 &+ &4\\
    \Rightarrow &1052676
\end{align*}
The overhead decreased to a mere $0.4\%$.
So bulk transfers obviously have a big benefit when using big block sizes.

But we cannot simply set a huge block size and be done, as now smaller messages are penalized.
Given our initial assumption of a small message of 40 bytes of data and a block length of 4096 bytes, we now have an overhead of $4096 - 40 - 16 - 4 = 4038$ bytes, that is $98\%$ of the block are unused.
As network connections tend to be slow, especially when transferring data via an uplink through the internet, this will severely hamper performance for small messages.

But even for networks where sending data is cheap the overhead would bring down throughput as we have to honor that data is encrypted.
The more data we need to send the longer it takes to encrypt and decrypt the message on both sides.

\medskip

As we can see, we need to make a compromise between either achieving high throughput for small or large messages.
As such, we have to determine exactly how big the effects we just described are and how they affect throughput.
To do so, we implemented a simple throughput benchmarking utility which is comprised of two threads sending data to each other.
The utility transmits 1GB of data to the remote side, where data is split into messages of a user-defined size.
This procedure is repeated for block lengths between 64 and 4096 bytes.

To simulate different network conditions, we use the previously described mechanisms to target different network latencies.
We have chosen three different scenarios of 0ms of latency for transfer on the host itself, 2ms of latency for transfer to remote systems on the same local area network and 20ms of latency for transfer to remote systems in the wide area network.

To estimate the effect of block lengths for different scenarios, we have chosen to send messages of four different lengths with 256 bytes, 1 kilobyte, 100 kilobytes and 10 megabytes of data.
The results can be seen in figure \ref{fig:block-length-benchmarks} visualized as graphs.
See appendix \ref{sec:appendix-throughput} for bare results.

\begin{figure}
    \centering

    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=200,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{256}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{256 bytes of data}
        \label{fig:block-length-benchmark-256b}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=400,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{1024}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{1 kilobyte of data}
        \label{fig:block-length-benchmark-1kb}
    \end{subfigure}

    \vspace{1em}

    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=750,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{102400}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{100 kilobytes of data}
        \label{fig:block-length-benchmark-100kb}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{0.4\textwidth}
        \resizebox*{!}{0.9\textwidth}
        {
            \begin{tikzpicture}
                \begin{axis}[ylabel=Throughput (in MB/s),ymax=750,xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench.csv};
                    \addlegendentry{0ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench-2ms.csv};
                    \addlegendentry{2ms latency}

                    \addplot table [x=pkglen,y=tpenc, col sep=comma,discard if not={datalen}{10240000}] {data/bench-20ms.csv};
                    \addlegendentry{20ms latency}

                    \addplot[mark=none, blue, dashed] coordinates { (64,120) (4096,120) };
                    \addplot[mark=none, orange, densely dotted] coordinates { (64,10) (4096,10) };
                \end{axis}
            \end{tikzpicture}
        }
        \caption{10 megabytes of data}
        \label{fig:block-length-benchmark-10mb}
    \end{subfigure}

    \caption{Sending data with different block lengths}
    \label{fig:block-length-benchmarks}
\end{figure}

The fours graphs display measurements for the different message sizes of 256 bytes, 1 kilobyte, 100 kilobytes and 10 megabytes.
Each of the figures has three different graphs representing the different scenarios for transfer of data on the same host and in LAN respectively WAN.
The x axis represents different block lengths in bytes used to split outgoing messages.
Please note that a logarithmic scale is used for block lengths.
The y axis represents the throughput achieved in megabytes per second averaged over the 1GB of data sent.
A higher value is better.

Additional constant dotted lines have been added to represent target throughput for Ethernet (blue dashed line, 120MB/s) and internet (orange densely dotted line, 10MB/s).connections .
These aim to put an estimated maximum achievable throughput which aids at better comprehending the chosen block length.

\medskip

Let us first discuss graphs \ref{fig:block-length-benchmark-256b} and \ref{fig:block-length-benchmark-1kb} as examples for transferring small messages to a remote host.

What stands out is that there throughput caps out at block lengths of 512 bytes for 256 byte messages and at block lengths of 1500 bytes for 1024 byte messages, respectively.
The reason for this is obvious: these are the smallest block lengths where the whole message fits into.
Regard that for a message of length $l$, the smallest block length that is big enough to fit is $l + 16 + 4$.
With smaller block lengths we have to send multiple blocks to transmit the whole message and with bigger messages we have to encrypt additional padding.
So the optimal block length for small messages is the smallest one where the whole message with metadata fits into.

One more interesting thing to observe is that with increasing latency, throughput decreases and features of the graphs seem to diminish.
While the spike in throughput is easily visible on 0ms and 2ms of latency, it becomes barely recognizable on 20ms of latency.
The effect of feature-flattening seems to get even more obvious the more data is sent, but this is effect results from a different maximum throughput value.

Let us take a look at graphs \ref{fig:block-length-benchmark-100kb} and \ref{fig:block-length-benchmark-10mb} now for examples of bulk transfer.
The effect of latency on throughput is very interesting for these graphs - while throughput constantly increases when there is no latency at all, it caps out at 200MB/s for 2ms of latency and at 50MB/s for 20ms of latency.

For 2ms of latency the cap is at around a block length of 1500 bytes.
The value of 1500 was included in the benchmarks as this is a typical size of the maximum transmission unit (MTU) for Ethernet connections.
The MTU is the size of the largest amount of data that can be sent in a single Ethernet frame without requirement to split the frame into multiple frames.
With this information, we have a possible explanation as to why throughput caps out at around 1500 bytes and decreases afterwards for 2ms of latency, while it steadily increases for 0ms of latency.
Sending two frames with latency will obviously have an impact on throughput, while it does not have a real impact when there is no latency.

\medskip

These benchmarks do not pay attention to maximum bandwidth available in LAN or WAN settings.
Usually, we cannot achieve more than around 100 megabytes per second in Gigabit Ethernet settings and around 10 megabytes per second in WAN settings.
We should honor this limitation when determining an optimal block length.

For small packages we are not able to reach the target throughput at for 2ms of latency and fail to meet the target starting at block lengths of 1024 for 20ms of latency when sending 256 byte messages.
For bulk transfer we start to hit the target in all scenarios when using a block length of 512 bytes.

\medskip

Let us subsume our findings from these benchmarks:
\begin{itemize}
    \item the optimum block length for short messages is the minimum block length able to fit in the complete message
    \item increasing block lengths will penalize short messages due to encryption overhead
    \item optimizing block length with high latencies is not useful due to throughput being near-flat
    \item optimal block length should not exceed length of the MTU (e.g. 1500 bytes)
\end{itemize}

To compromise between throughput for small and bulk traffic we chose a block length of 512 bytes.
It is the smallest block length able to achieve all target throughputs except for small messages with 2ms of latency, but we do not expect to need high throughput for small messages.

It may be desirable to make the block length configurable per service.
Services usually know their communication patterns and can thus optimize for the respective scenario they require.
Currently no such feature exists, but the block length is trivially changeable at compile time and as such it would a small feat to make block lengths configurable at runtime.

\subsubsection{Connection establishment latency}

The second benchmark involves connection establishment latency.
When a client connects to servers, the first thing that is always performed is negotiation of an ephemeral key, which requires a total of three messages being exchanged between all parties.
In this benchmark, we want to determine how the complete sequence of key negotiation performs under different networking settings and how this is influenced by different block lengths.

To test the connection establishment process, we wrote a simple benchmarking utility.
The utility consists of a client and a server thread, where the client repeatedly connects to the server, initiates the key exchange protocol and then disconnects again.
The whole process is repeated 1000 times in order to increase the timing's validity.

See figure \ref{fig:connection-establishment} for the results visualized as a graph and appendix \ref{sec:appendix-connection-establishment} for the bare timings.
The horizontal axis displays the block length in bytes, that is what is size of the fixed-size blocks used to split messages by.
The block length is measured in a logarithmic scale ranging from 64 bytes up to 4096 bytes.
The vertical axis displays the overall time required for the complete connection establishment process in milliseconds.
Each of the three graphs represents a networking condition with a different latency.

Displayed is only the time required for the client to connect and initiate the algorithm, as the server has to perform the same steps without the initial connection establishment and only sends one of the three messages.
So timings on the client side result in more interesting measurements.
Appendix \ref{sec:appendix-connection-establishment} contains both client and server timings, though.

\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        \begin{axis}[ylabel=Connection time (in ms),xmode=log,xlabel={Block length (logarithmic scale, in bytes)}]
            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{0}] {data/latency.csv};
            \addlegendentry{0ms latency}

            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{2}] {data/latency.csv};
            \addlegendentry{2ms latency}

            \addplot table [x=pkglen,y=connect, col sep=comma,discard if not={latency}{20}] {data/latency.csv};
            \addlegendentry{20ms latency}
        \end{axis}
    \end{tikzpicture}
    \caption{Connection establishment latency}
    \label{fig:connection-establishment}
\end{figure}

We can see that the computational overhead induced by encryption and exchange of the messages is near-negligible as without latency, we do not even reach 1ms of required time.
So the graph for same-host communication seems uninteresting as no distinct features can be seen.
In fact, though, there is a $5\%$ decrease in time required to do the initiation for block lengths of 64 bytes to block lengths of 256 bytes.
Each message sent in the key exchange contains exactly 134 bytes, which surmounts to a total of 138 bytes including the package length and excluding encryption, which is not used in this step.
As such, a block length of 256 bytes is the optimum block length of the block lengths exercised, as it is the first one able to fit all data in one message.

Interestingly there is another increase in performance of around $4\%$ between block lengths of 256 bytes and 512 bytes, which cannot be explained by message splitting as both block lengths are sufficient.
In fact, one would rather expect a decrease in performance as there is additional overhead required to send additional padding.
As repeated benchmarks have resulted in the same results, it is unlikely that this is caused by measurement anomalies, even though we operate in microsecond-ranges.
Up to now, we are unable to explain this behavior.

For the other two graphs with 2 and 20 milliseconds of packet delay, the results are as one would expect.
There is a harsh decrease of connection establishment time as soon as we exceed the size of messages sent.
This improve in efficiency can be seen especially for 20ms of latency, as we effectively cut the blocks required in half and each block induces some latency.

For both graphs with latency one can easily see that we have a connection establishment latency of the number of blocks sent multiplicated by the latency plus the latency induced by the initial connection to the server.
Exceeding the sent message's size, this can be summarized by the formula $t = 4 \times l + c$, where $t$ is the time required for the complete connection establishment protocol, $l$ is the latency and $c$ is a sub-millisecond constant for calculations regarding key derival.

For slow connections with a packet delay of up to 250ms we would still be able to perform connection establishment in around one second.
Considering that connection establishments are only performed at most three times for a service invocation (that is querying the service, creating a session and start the session), this should be sufficient.

\subsubsection{Input latency}

The last benchmark done aims to determine how the framework performs for interactive processes.
The scenario is simple: given a user connected to a service forwarding its input to another server, how long does it take until an input event issued by the user to arrive at that server and be processed by the display server?

The current implementation has a service providing input forwarding by using the Synergy protocol (see section \ref{sec:synergy-service} for more details on the implementation).
So we want to perform benchmarks on how long it does take to forward input events via Synergy, ideally in different scenarios.
We need a way to measure when a certain event is generated and when it arrives at the server.

The X protocol is developed with no real security built in.
While usually considered as a detriment to the X protocol as it becomes impossible to separate graphical applications and inputs from each other, it is of great benefit for us as we are able to utilize it to do these measurements.
The idea is to create two framebuffers separated from each other, connect these framebuffers via Synergy, hook them up to receive events and then determine how long it does take when an event is generated in the first framebuffer to arrive in the second framebuffer

The concrete implementation instantiates two X virtual frame buffers (Xvfb), which do not render to hardware but instead to virtual memory.
We then connect these virtual framebuffers either directly by a Synergy client and server, or via the service framework tunneling Synergy's data.

As the setup is complete, we want to be able to get timing information for generated and received events.
For this, we have written a simple program which basically connects to both Xvfbs and tells these displays that it wishes to receive all input events generated and then monitors both sockets to the display for incoming events, calculating the delay between the event's generation and receive.

One problem experienced is that in order to receive all events, we usually have to grab the input devices.
As they often are already grabbed by e.g. a window manager or other X clients, we are unable to do so.
To circumvent this problem, we instead use the XInput2 extension to the X protocol to receive all input events without the requirement to first grab devices and as such monitor all events without interfering with other X clients.

The program also spawns another thread which has the task to generate input events.
Instead of manually generating events by e.g. clicking the mouse (which becomes hard to do in virtual framebuffers), we use the XTest extension of the X protocol to generate a fixed amount of input events.
On the receiving side, we now wait for all these input events to arrive and then stop the testing sequence.

While testing it has been experienced that single X events may get dropped, leading us to block on receiving the missing events.
A workaround employed by us is to generate a fixed amount of events, but waiting only on the first $x$ events to arrive and calculate the delay based on these events only.
One more problem is that we do not match events with each other, that is we only monitor \emph{if} there are events arriving and not if these events are really the ones we have just generated.
As we use virtual framebuffers, though, the likelihood that stray X events are generated in these is low if no other X clients are attached to them.

Furthermore we have note that timings are very vague as with network connections, multiple virtual X servers and event generation there are a lot of variables, so we need to keep in mind that deviations are very likely.

See appendix \ref{sec:appendix-input-latency} for bare results, figure \ref{fig:input-latency} shows the graphs resulting from the measurements.
The horizontal axis displays the block lengths in a logarithmic scale in bytes, starting at 64 bytes and going up to 4096 bytes.
The vertical axis displays the input delay in milliseconds, which is the total amount required to receive 1000 repeated clicks.
The graphs represent measurements under different network conditions.

One added detail are the three horizontal bars, where each of these bars corresponds to one latency based on its style.
These bars mark the timings for input delay when the Synergy service and client are connected to each other without tunneling data through our service framework and should act as a reference.

\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        \begin{axis}[ylabel=Input delay (in ms),xmode=log,ymax=1450,xlabel={Block length (logarithmic scale, in bytes)},xmax=7500]
            \pgfplotsinvokeforeach {0, 2, 20} {
                \addplot table [forget plot,x=pkglen,y=delay, col sep=comma,discard if not={latency}{#1}] {data/input.csv};
                \addlegendentry {#1ms latency}
                \addplot+[mark=none,xcomb] table [x expr=7500,y=delay, col sep=comma,discard if not={pkglen}{0},discard if not={latency}{#1}] {data/input.csv};
            }
        \end{axis}
    \end{tikzpicture}
    \caption{Input latency}
    \label{fig:input-latency}
\end{figure}

% grep '^0' docs/thesis/data/input.csv | awk '{ split ($0, v, ","); if (NR == 1) { ref=v[3] } else { sum += v[3] } } END { print (sum / (NR - 1)) / ref }'

In the scenario of same-host communication, our framework performs very close to the plain Synergy solution.
But as latency raises, using the service framework puts an increasing penalty on input latency.
While we cannot observe a statistically significant difference between using the service and plain Synergy on same-host communication, we perform around $1\%$ worse than the reference value at 2ms of latency, which increases to around $6\%$ worse at 20ms of latency compared to the reference value.
The divergence is expected to grow worse for higher latencies.

Interestingly, block lengths do not have any impact for these benchmarks.
In more constrained environments where bandwidth is limited this changes so that with increasing block lengths, the input delay will increase the more input events are sent.
E.g. assuming a maximum bandwidth of 100kbit/s, input events would be limited to a maximum of 25 events when we have a block length of 4096.
While enough for simple clicks or key strokes, mouse movement will be impacted.

This observation makes a case for small block lengths for interactive services.
But as small block lengths have an impact on services which require high throughput instead of low latency we have a direct contradiction.
One obvious solution is to adjust block lengths for different services.
While it is already possible to adjust block lengths for a single communication channel, no service currently does this but instead they currently use the default configuration of 512 bytes.

It would be trivial to adjust block lengths when a service starts handling a session's channel when both client and server simply set block lengths based on what service type is invoked.
More complicated solutions could have some kind of link negotiation between client and server where both parties could settle for a common block length.
A link negotiation would also enable to accommodate for different networking settings, where there is a training phase where both parties test the connection and afterwards settle on a block length based on gained knowledge and the service type that is to be used.

\subsection{Development process}

The complete software stack is split up into two major components, namely the server-side part and the controller application for Android.
While these two components are strictly split up in functionality and dependencies, they still reside in a mono-repository so that it becomes easier to modify the core protocol and adjust both sides to work with the new version.

The server-side stack is written in the C programming language and currently clocks in at 6680 source lines of code excluding empty lines and comments.
Code is logically split up into a set of executables and libraries like following:
\begin{description}
    \item[Benchmarking]\hfill\\
        Two executables exist that drive the logic behind the benchmarks described in section \ref{sec:benchmarking}, where \emph{sd-bench} handles logic around throughput-benchmarks and \emph{sd-latency} estimates connection establishment latency.
    \item[Discovery]\hfill\\
        Service discovery is handled by \emph{sd-discovery-server} with a complementary executable \emph{sd-discover} used for testing the server implementation.
        It handles the process of directed and multicast server discovery as described in section \ref{sec:discovery}.
    \item[Server]\hfill\\
        The server executable \emph{sd-server} implements session management as well as handing off incoming connections to the requested service plugins.
        To drive the server from command line, another executable \emph{sd-client} has been written, that is able to query the server for details, request and start sessions.
    \item[Services]\hfill\\
        The services component contains the services implemented and described before in section \ref{sec:services}.
    \item[Library]\hfill\\
        Most functionality, most importantly the core protocol as well as the session handling, has been written such that it is layed out in a single shared object with a documented interface.
        Like this it is easy to re-use logic in different executables or even in other projects.
        One more great benefit is that with a library-style interface, it is easy to drive unit tests on the library's interface.
    \item[Tests]\hfill\\
        Unit tests exist that cover much of the logic of the core library.
\end{description}

Table \ref{tab:sloc} summarizes the source lines of code per component, where the column ``Lines of source code'' counts the actual lines of code excluding comments and whitespace and the column ``Total lines'' counts the total amount of lines.
\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \bfseries Component & \bfseries Lines of source code & \bfseries Total lines\\
        \hline
        Benchmarking & 293 & 405\\
        \hline
        Discovery & 331 & 456\\
        \hline
        Server & 515 & 678\\
        \hline
        Services & 971 & 1523\\
        \hline
        Library & 2407 & 4798\\
        \hline
        Tests & 2075 & 2811 \\
        \hline
    \end{tabular}
    \caption{Lines of code per component for server}
    \label{tab:sloc}
\end{table}

A great emphasis has been put on cross-platform support.
As such, the code is written in strict ISO C90 \cite{iso-c90} which is supported by all modern compilers.
To guarantee that the code actually works on multiple platforms, multiple continuous integration (CI) services have been set up.
The CI services get notified on the event that a new commit has been pushed to a monitored repository and if so, they fetch the changes, build the applications and execute tests.
Currently, there are two CI services have been registered:
\begin{itemize}
    \item Travis CI \cite{travis} provides Linux and OS X build platforms
    \item AppVeyor \cite{appveyor} provides Windows build platforms
\end{itemize}

The project uses the Git source control management system \cite{git} and GitHub as its hosting platform \cite{github}.
In order to have a clean development process and a main branch which is always potentially releasable, that is it always builds and unit tests pass on all platforms, a development process is specified making heavy use of branches.
Every unit of development, e.g. a new feature, bugfixing or refactoring, is done in a separate branch which is then pushed to the main repository where it is picked up by the CI services.
As soon as all CI services have determined that the changes do not break the build on any platform and that all unit tests pass, the branch can be merged into the mainline.

As the C programming language requires manual resource management it is important to verify that the executables have no resource leaks and do not try to access resources that are not available anymore.
Most importantly, this involves checking for invalid memory dereferences, buffer overflows and memory leaks which are commonly used in attempts to exploit applications.

To work against this threat, special CI jobs exist which utilize the address and undefined behavior sanitizers of the GNU compiler collection (GCC) \cite{gcc}.
Executables compiled with these features enabled instrument the application in a specific way in order to analyze the application at run-time for invalid address references or for code relying on undefined behavior.
Like this, it is possible to catch programming errors related to referencing uninitialized memory, out-of-bounds array access, memory leaks and more.
The CI jobs execute the test suite with these flags enabled and report errors encountered during the execution.

One more service has been set up with Coverity Scan \cite{coverity}.
Code submitted to it will be analyzed at build time and submitted to the service, which then performs static analysis on source code level.
In contrast to the aforementioned CI services, Coverity Scan does not only analyze code which is actually executed while running the unit tests but covers the complete source code.
It is able to catch a lot of errors like invalid memory access and leaked file descriptors, but also catches other errors like time-of-check-time-of-use errors or problems related to multithreading.

\bigskip

The second component of the ecosystem is the controller application for Android mobile phones.
As the Android operating system provides a development environment based on the Dalvik Virtual Machine, the main programming language used to develop Android applications is the Java programming language.

As with the parts written in C, some effort has been done to have a clean separation between the protocol libraries and low-level functionality and the actual user interface.
The total controller application is around 2660 lines of actual code which can be split up into the following components:
\begin{description}
    \item[User interface]\hfill\\
        The user interface provides all functionality directly presented to the user.
        Core functionality currently provided by the application includes key management for the user's long term signature key, service discovery and favorites-management as well is the invocation of services.
    \item[Service plugins]\hfill\\
        Service plugins provide implementations for actual services which can be started.
        As of now, three service plugins have been implemented for the controller:
        \begin{itemize}
            \item a capability plugin handling the relay of capabilities as described in \ref{sec:capability-service}
            \item an invoke plugin causing a server to invoke another service chosen by the user as described in \ref{sec:invoke-service}
            \item an exec plugin handling execution of programs on remote servers as described in \ref{sec:exec-service}
        \end{itemize}
    \item[Protocol]\hfill\\
        This module implements the protocol.
        This includes the low-level protocol used by channels as described in \ref{sec:low-level-protocol} and the messages exchanged for querying, session establishment and session invocation as described in section \ref{sec:protocol}.
\end{description}

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \bfseries Component & \bfseries Lines of source code & \bfseries Total lines\\
        \hline
        User interface & 968 & 1357\\
        \hline
        Service plugins & 711 & 1022\\
        \hline
        Protocol & 982 & 1513\\
        \hline
    \end{tabular}
    \caption{Lines of code per component for Android controller}
    \label{tab:sloc-controller}
\end{table}

Table \ref{tab:sloc-controller} provides an overview over the amount of code per component.

Due to timing constraints no tests are available for the Android application and no CI services have been set up.

% vim: ft=tex tw=0
